{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "from difflib import SequenceMatcher\n",
    "import salem\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import os\n",
    "import shapely.geometry as shpg\n",
    "import shapely.ops\n",
    "import collections\n",
    "from shapely.geometry import Point, shape\n",
    "import fiona\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\database_Fischer_et_al._2015_The_Cryosphere.txt'                 # Fischer database with swiss coordinates \n",
    "fll_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\SGI2010wgs84_shapefiles\\\\parameters_SGI2010.csv'               # Fischer database with lat/lon\n",
    "a_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\DOI-WGMS-FoG-2015-11\\\\WGMS-FoG-2015-11-A-GENERAL-INFORMATION.csv'# FoG: A GENERAL\n",
    "b_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\DOI-WGMS-FoG-2015-11\\\\WGMS-FoG-2015-11-B-STATE.csv'              # FoG: B STATE\n",
    "d_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\DOI-WGMS-FoG-2015-11\\\\WGMS-FoG-2015-11-D-CHANGE.csv'             # FoG: D CHANGE\n",
    "gl_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\glims_db_20160429\\\\glims_polygons_swiss_alps.txt'               # GLIMS DBF file\n",
    "ch_adm_path = \"C:\\\\Users\\\\jlandman\\\\Desktop\\\\CHE_adm_shp\\\\CHE_adm1.shp\"                                  # Swiss Kanton borders\n",
    "rgi_CE = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\rgi50\\\\11_rgi50_CentralEurope\\\\11_rgi50_CentralEurope.shp'       # RGI 5.0 Central Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(f_path, sep = '\\t', encoding='iso-8859-1')\n",
    "pdfll = pd.read_csv(fll_path, sep= ';', encoding='iso-8859-1')  #, usecols=[2,3,6,14,15]\n",
    "pda = pd.read_csv(a_path, encoding='iso-8859-1')\n",
    "pdb = pd.read_csv(b_path, encoding='iso-8859-1')\n",
    "pdd = pd.read_csv(d_path, encoding='iso-8859-1')\n",
    "glims = pd.read_csv(gl_path, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preselect FoG IDs in Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda = pda[pda.POLITICAL_UNIT == 'CH']\n",
    "pdb = pdb[pdb.WGMS_ID.isin(pda.WGMS_ID.values)]\n",
    "pdd = pdd[pdd.WGMS_ID.isin(pdd.WGMS_ID.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haversine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct missing underscores and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = pdf.rename(columns={'uncertainty_dvol_between_t1_and_t2_mio m3': 'uncertainty_dvol_between_t1_and_t2_mio_m3'})\n",
    "pdfll = pdfll.rename(columns={'uncertainty_dvol_between_t1_and_t2_mio m3': 'uncertainty_dvol_between_t1_and_t2_mio_m3'})\n",
    "\n",
    "pdfll = pdfll.rename(columns={'Unnamed: 15': 'Glacier_name_SGI2010'})\n",
    "pdfll = pdfll.rename(columns={'Unnamed: 16': 'year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach: find matching glaciers based on FoG => compare names, area and location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of strings and symbols that should be replaced prior to calculation of similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_adjust = {'gletscher':'g', 'glacier':'g' , 'vadret':'v', 'ghiacciaio':'g', 'vedretta':'v', 'ferner':'f', 'ä':'ae', 'ö':'oe', 'ü':'ue', 'é':'e', 'à':'a', 'è':'e', 'ô':'o', 'ß':'ss'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce FoG column with new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda['FoG_compname'] = ''\n",
    "\n",
    "for initname in [n for n in pda.NAME.values]:\n",
    "    name = initname.lower()\n",
    "    for key in name_adjust:\n",
    "        if key in name:\n",
    "            name = name.replace(key, name_adjust[key])\n",
    "    #pda.FoG_compname[pda.NAME == initname] = name\n",
    "    pda.loc[pda.NAME == initname, 'FoG_compname'] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce some new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf.COMPNAME = ''              # simplified name \n",
    "pda.MATCH_RATIO = np.nan       # string matching ratio \n",
    "pda.MATCH_NAME = ''            # Name of the FoG glacier that matches Mauro's name best\n",
    "pda.CLOSEST = ''               # closest FoG glacier point\n",
    "pda.DIST_TO_CLOSEST = np.nan   # distance of Mauro's point to the closest FoG point \n",
    "pda.AREA_CLOSEST = np.nan      # column with the area of Mauro's glacier found by string matching \n",
    "pda.AREA_MATCH = np.nan        # column with the area of Mauro's glacier found by string matching\n",
    "pda.AREA = np.nan              # Area that will be grabbed from the PDB file, if present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust also Mauro's names to make them comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx,cols in pdf.iterrows():\n",
    "    # simplify name\n",
    "    compname_mau = cols.Glacier_name_SGI2010.lower()\n",
    "    for key in name_adjust:\n",
    "        if key in compname_mau:\n",
    "            # replace the umlauts etc.\n",
    "            compname_mau = compname_mau.replace(key, name_adjust[key])\n",
    "    \n",
    "    # delete the bracket stuff in order to improve the ratio\n",
    "    start = compname_mau.find('(')\n",
    "    if start != -1:\n",
    "        compname_mau = compname_mau[0:start]\n",
    "    compname_mau = compname_mau.replace('*', '')\n",
    "    compname_mau = compname_mau.strip()\n",
    "\n",
    "    pdf.loc[pdf.Glacier_name_SGI2010 == cols.Glacier_name_SGI2010, 'COMPNAME'] = compname_mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdfll.COMPNAME = ''              # simplified name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx,cols in pdfll.iterrows():\n",
    "    # simplify name\n",
    "    compname_mau = cols.Names.lower()\n",
    "    for key in name_adjust:\n",
    "        if key in compname_mau:\n",
    "            # replace the umlauts etc.\n",
    "            compname_mau = compname_mau.replace(key, name_adjust[key])\n",
    "    \n",
    "    # delete the bracket stuff in order to improve the ratio\n",
    "    start = compname_mau.find('(')\n",
    "    if start != -1:\n",
    "        compname_mau = compname_mau[0:start]\n",
    "    compname_mau = compname_mau.replace('*', '')\n",
    "    compname_mau = compname_mau.strip()\n",
    "\n",
    "    pdfll.loc[pdfll.Names == cols.Names, 'COMPNAME'] = compname_mau\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matching glaciers for the 159 swiss glaciers in PDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A NEUVE GL. L'\n",
      "ADLER\n",
      "ALBIGNA\n",
      "ALLALIN\n",
      "ALPETLI(KANDER)\n",
      "ALTELS\n",
      "AMMERTEN\n",
      "AROLLA (BAS)\n",
      "BALMHORN\n",
      "BASODINO\n",
      "BELLA TOLA\n",
      "BIDER\n",
      "BIFERTEN\n",
      "BIRCH\n",
      "BIS\n",
      "BLUEMLISALP\n",
      "BODMER\n",
      "BOVEYRE\n",
      "BREITHORN\n",
      "BRENEY\n",
      "BRESCIANA\n",
      "BRUNEGG\n",
      "BRUNNI\n",
      "CALDERAS\n",
      "CAMBRENA\n",
      "CAVAGNOLI\n",
      "CHEILLON\n",
      "CLARIDENFIRN\n",
      "CORBASSIERE\n",
      "CORNO\n",
      "CROSLINA\n",
      "DAMMA\n",
      "DOLENT GL. DU\n",
      "DUNGEL\n",
      "EIGER\n",
      "EIGER (WEST)\n",
      "EN DARREY\n",
      "FEE NORTH\n",
      "FERPECLE\n",
      "FIESCHER\n",
      "FINDELEN\n",
      "FIRNALPELI\n",
      "FLUCHTHORN GL.\n",
      "FORNO\n",
      "GAMCHI\n",
      "GAULI\n",
      "GELTEN\n",
      "GIETRO\n",
      "GLAERNISCH\n",
      "GORNER\n",
      "GRAND DESERT\n",
      "GRAND PLAN NEVE\n",
      "GRIES\n",
      "GRIESS(KLAUSEN)\n",
      "GRIESSEN(OBWA.)\n",
      "GRIESSERNU\n",
      "GROSSER ALETSCH\n",
      "GRUBEN\n",
      "GUTZ\n",
      "HANGENDE\n",
      "HINDRE SCHMADRI\n",
      "HOHLAUB\n",
      "HOMATTU\n",
      "HUEFI\n",
      "KALTWASSER\n",
      "KEHLEN\n",
      "KESSJEN\n",
      "LAEMMERN (WILDSTRUBEL)\n",
      "LANG\n",
      "LAVAZ\n",
      "LENTA\n",
      "LIMMERN\n",
      "LISCHANA\n",
      "MAIGHELS EAST BRANCH\n",
      "MAIGHELS WEST BRANCH\n",
      "MARTINETS\n",
      "MINSTIGER\n",
      "MITTELALETSCH\n",
      "MOIRY\n",
      "MOMING\n",
      "MONT DURAND\n",
      "MONT FORT (ZINAL)\n",
      "MONT MINE\n",
      "MONTO MORO GL.\n",
      "MORTERATSCH\n",
      "MURTEL\n",
      "MUTT\n",
      "MUTTEN\n",
      "OB.GRINDELWALD\n",
      "OBERAAR\n",
      "OBERALETSCH\n",
      "OFENTAL\n",
      "OTEMMA\n",
      "PALUE\n",
      "PANEYROSSE\n",
      "PARADIES\n",
      "PARADISINO (CAMPO)\n",
      "PIERREDAR\n",
      "PIZOL\n",
      "PLAINE MORTE\n",
      "PLATTALVA\n",
      "PORCHABELLA\n",
      "PRAPIO\n",
      "PUNTEGLIAS\n",
      "RAETZLI (PLAINE MORTE)\n",
      "RHONE\n",
      "RIED\n",
      "ROSEG\n",
      "ROSENLAUI\n",
      "ROSSBODEN\n",
      "ROTFIRN NORD\n",
      "ROTTAL\n",
      "SALEINA\n",
      "SANKT ANNA\n",
      "SARDONA\n",
      "SCALETTA\n",
      "SCHOENBUEHL GL.\n",
      "SCHWARZ\n",
      "SCHWARZBACH\n",
      "SCHWARZBERG\n",
      "SEEWJINEN\n",
      "SESVENNA\n",
      "SEX ROUGE\n",
      "SILLERN\n",
      "SILVRETTA\n",
      "SIRWOLTE\n",
      "STEIN\n",
      "STEINLIMMI\n",
      "SULZ\n",
      "SURETTA\n",
      "TAELLIBODEN\n",
      "TIATSCHA\n",
      "TIEFEN\n",
      "TOURNELON BLANCE\n",
      "TRIENT\n",
      "TRIEST GL.\n",
      "TRIFT (GADMEN)\n",
      "TSANFLEURON\n",
      "TSCHIERVA\n",
      "TSCHINGEL\n",
      "TSEUDET\n",
      "TSIDJIORE NOUVE\n",
      "TURTMANN (WEST)\n",
      "UNT.GRINDELWALD\n",
      "UNTERAAR\n",
      "VAL TORTA\n",
      "VALLEGGIA\n",
      "VALSOREY\n",
      "VERSTANKLA\n",
      "VORAB\n",
      "VORDRE SCHMADRI\n",
      "WALLENBUR\n",
      "WANNENHORN GL.\n",
      "WANNENHORN GL. N\n",
      "WANNENHORN GL. S\n",
      "WITENWASSEREN\n",
      "ZENBAECHEN GL.\n",
      "ZINAL\n",
      "ZMUTT\n"
     ]
    }
   ],
   "source": [
    "#if os.path.exists('assigned_automated.csv'):\n",
    "#    pass\n",
    "\n",
    "#else:\n",
    "for fidx,fcols in pda.iterrows():\n",
    "\n",
    "    # create an AREA column entry (from the PDB (\"state\") table)\n",
    "    area_match = np.nan\n",
    "    try: # take the latest area entry\n",
    "        area_match = pdb[pdb.WGMS_ID == fcols.WGMS_ID].AREA.values[~np.isnan(pdb[pdb.WGMS_ID == fcols.WGMS_ID].AREA.values)][-1]\n",
    "    except IndexError:\n",
    "        area_match = np.nan\n",
    "    pda.loc[pda.WGMS_ID == fcols.WGMS_ID, 'AREA'] = area_match\n",
    "\n",
    "\n",
    "    # find biggest ratio of string matching and insert\n",
    "    ratio = 0.0\n",
    "    name = ''\n",
    "    for cname in pdfll['COMPNAME'].values:\n",
    "        curr_ratio = SequenceMatcher(None, cname, fcols.FoG_compname).ratio()\n",
    "\n",
    "        if curr_ratio > ratio or ratio==0.0:  #the latter in order to catch the initial case\n",
    "            ratio = curr_ratio\n",
    "            name = cname\n",
    "\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'MATCH_RATIO'] = ratio\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'MATCH_NAME'] = name\n",
    "\n",
    "    # insert the area (at t2, because this is the latest) of the glacier found by string matching\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'AREA_MATCH'] = pdfll[pdfll['COMPNAME'] == name]['area(km2)'].iloc[0]\n",
    "\n",
    "\n",
    "    #find closest pdf glacier\n",
    "    dist = np.nan\n",
    "    close_name = ''\n",
    "    for pdf_idx, pdf_cols in pdfll.iterrows():\n",
    "        lat = pdfll[pdfll.Names == pdf_cols.Names]['y WGS84)'].values[0]\n",
    "        lon = pdfll[pdfll.Names == pdf_cols.Names]['Location(x WGS84)'].values[0]\n",
    "        curr_dist = haversine(lon, lat, fcols.LONGITUDE, fcols.LATITUDE)\n",
    "\n",
    "        if curr_dist < dist or pd.isnull(dist): # the second is for the initial loop\n",
    "            dist = curr_dist\n",
    "            close_name = pdf_cols.COMPNAME\n",
    "\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'DIST_TO_CLOSEST'] = dist\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'CLOSEST'] = close_name\n",
    "\n",
    "    print(fcols.NAME)\n",
    "    # insert the area (at t2, because this is the latest) of the glacier ehic is found to be the closest\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'AREA_CLOSEST'] = pdfll[pdfll['COMPNAME'] == close_name]['area(km2)'].iloc[0]\n",
    "\n",
    "\n",
    "    pda.to_csv('assigned_automated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pda.to_csv('assigned_automated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Okay the automated assignment is not always good (high polygon density, too many similar names...) => Check everything manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 'BREITHORN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID = pda[pda.NAME == i].WGMS_ID.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLITICAL_UNIT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WGMS_ID</th>\n",
       "      <th>RIVER_BASIN</th>\n",
       "      <th>FREE_POSITION</th>\n",
       "      <th>LOCAL_CODE</th>\n",
       "      <th>LOCAL_PSFG</th>\n",
       "      <th>GEN_LOCATION</th>\n",
       "      <th>SPEC_LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>...</th>\n",
       "      <th>GEO-REGION_CODE</th>\n",
       "      <th>GEO-SUBREGION_CODE</th>\n",
       "      <th>FoG_compname</th>\n",
       "      <th>AREA</th>\n",
       "      <th>MATCH_RATIO</th>\n",
       "      <th>MATCH_NAME</th>\n",
       "      <th>AREA_MATCH</th>\n",
       "      <th>DIST_TO_CLOSEST</th>\n",
       "      <th>CLOSEST</th>\n",
       "      <th>AREA_CLOSEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>CH</td>\n",
       "      <td>BREITHORN</td>\n",
       "      <td>2311</td>\n",
       "      <td>4R014</td>\n",
       "      <td>4M</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.48</td>\n",
       "      <td>...</td>\n",
       "      <td>CEU</td>\n",
       "      <td>CEU-01</td>\n",
       "      <td>breithorn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>breithorng</td>\n",
       "      <td>2.71188</td>\n",
       "      <td>143.257626</td>\n",
       "      <td>tschingelhorn-ne</td>\n",
       "      <td>0.01787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    POLITICAL_UNIT       NAME  WGMS_ID RIVER_BASIN FREE_POSITION LOCAL_CODE  \\\n",
       "711             CH  BREITHORN     2311       4R014            4M         19   \n",
       "\n",
       "    LOCAL_PSFG GEN_LOCATION SPEC_LOCATION  LATITUDE     ...       \\\n",
       "711        NaN          NaN           NaN     46.48     ...        \n",
       "\n",
       "     GEO-REGION_CODE  GEO-SUBREGION_CODE FoG_compname  AREA MATCH_RATIO  \\\n",
       "711              CEU              CEU-01    breithorn   NaN    0.947368   \n",
       "\n",
       "     MATCH_NAME  AREA_MATCH DIST_TO_CLOSEST           CLOSEST AREA_CLOSEST  \n",
       "711  breithorng     2.71188      143.257626  tschingelhorn-ne      0.01787  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pda[pda.NAME == i]#[['LATITUDE', 'LONGITUDE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLITICAL_UNIT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WGMS_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>HIGHEST_ELEVATION</th>\n",
       "      <th>MEDIAN_ELEVATION</th>\n",
       "      <th>LOWEST_ELEVATION</th>\n",
       "      <th>ELEVATION_UNC</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>LENGTH_UNC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA_UNC</th>\n",
       "      <th>SURVEY_DATE</th>\n",
       "      <th>SURVEY_PLATFORM_METHOD</th>\n",
       "      <th>PUB_IN_FOG</th>\n",
       "      <th>INVESTIGATOR</th>\n",
       "      <th>SPONS_AGENCY</th>\n",
       "      <th>REFERENCE</th>\n",
       "      <th>REMARKS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [POLITICAL_UNIT, NAME, WGMS_ID, YEAR, HIGHEST_ELEVATION, MEDIAN_ELEVATION, LOWEST_ELEVATION, ELEVATION_UNC, LENGTH, LENGTH_UNC, AREA, AREA_UNC, SURVEY_DATE, SURVEY_PLATFORM_METHOD, PUB_IN_FOG, INVESTIGATOR, SPONS_AGENCY, REFERENCE, REMARKS]\n",
       "Index: []"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb[pdb.where(~pd.isnull(pdb.AREA)).WGMS_ID == ID].tail(10)#[['NAME', 'LENGTH', 'AREA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>acquisition date</th>\n",
       "      <th>Location(x WGS84)</th>\n",
       "      <th>y WGS84)</th>\n",
       "      <th>Location(x CH1903</th>\n",
       "      <th>y CH1903)</th>\n",
       "      <th>area(km2)</th>\n",
       "      <th>min_elevation (masl)</th>\n",
       "      <th>max_elevation (masl)</th>\n",
       "      <th>median_elevation (masl)</th>\n",
       "      <th>average_elevation (masl)</th>\n",
       "      <th>length (km)</th>\n",
       "      <th>average_slope (degree)</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Names</th>\n",
       "      <th>Glacier_name_SGI2010</th>\n",
       "      <th>year</th>\n",
       "      <th>COMPNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>A51F_50</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.49390</td>\n",
       "      <td>46.770802</td>\n",
       "      <td>680737.8</td>\n",
       "      <td>180533.1</td>\n",
       "      <td>0.13422</td>\n",
       "      <td>2503</td>\n",
       "      <td>2731</td>\n",
       "      <td>2590</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>30.9</td>\n",
       "      <td>SE</td>\n",
       "      <td>CHÜEFADFIRN-W</td>\n",
       "      <td>A51F/50</td>\n",
       "      <td>2010</td>\n",
       "      <td>chueefadfirn-w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>A51F_80n</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.50702</td>\n",
       "      <td>46.772499</td>\n",
       "      <td>681526.2</td>\n",
       "      <td>180689.3</td>\n",
       "      <td>0.02920</td>\n",
       "      <td>2491</td>\n",
       "      <td>2623</td>\n",
       "      <td>2545</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>28.7</td>\n",
       "      <td>SE</td>\n",
       "      <td>Chüefadstock* (Teilgl. von A51F/51)</td>\n",
       "      <td>A51F/80n</td>\n",
       "      <td>2010</td>\n",
       "      <td>chueefadstock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>A51F_81n</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.50842</td>\n",
       "      <td>46.777000</td>\n",
       "      <td>681815.8</td>\n",
       "      <td>181089.3</td>\n",
       "      <td>0.23469</td>\n",
       "      <td>2562</td>\n",
       "      <td>2901</td>\n",
       "      <td>2786</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>0.867</td>\n",
       "      <td>21.8</td>\n",
       "      <td>S</td>\n",
       "      <td>Chüefadfirn-E* (Teilgl. von A51F/51)</td>\n",
       "      <td>A51F/81n</td>\n",
       "      <td>2010</td>\n",
       "      <td>chueefadfirn-e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  acquisition date  Location(x WGS84)   y WGS84)  \\\n",
       "306   A51F_50              2010            8.49390  46.770802   \n",
       "330  A51F_80n              2010            8.50702  46.772499   \n",
       "331  A51F_81n              2010            8.50842  46.777000   \n",
       "\n",
       "     Location(x CH1903  y CH1903)  area(km2)  min_elevation (masl)  \\\n",
       "306           680737.8   180533.1    0.13422                  2503   \n",
       "330           681526.2   180689.3    0.02920                  2491   \n",
       "331           681815.8   181089.3    0.23469                  2562   \n",
       "\n",
       "     max_elevation (masl)  median_elevation (masl)  average_elevation (masl)  \\\n",
       "306                  2731                     2590                    2592.0   \n",
       "330                  2623                     2545                    2546.0   \n",
       "331                  2901                     2786                    2770.0   \n",
       "\n",
       "     length (km)  average_slope (degree) aspect  \\\n",
       "306        0.327                    30.9     SE   \n",
       "330        0.243                    28.7     SE   \n",
       "331        0.867                    21.8      S   \n",
       "\n",
       "                                    Names Glacier_name_SGI2010  year  \\\n",
       "306                         CHÜEFADFIRN-W              A51F/50  2010   \n",
       "330   Chüefadstock* (Teilgl. von A51F/51)             A51F/80n  2010   \n",
       "331  Chüefadfirn-E* (Teilgl. von A51F/51)             A51F/81n  2010   \n",
       "\n",
       "           COMPNAME  \n",
       "306  chueefadfirn-w  \n",
       "330   chueefadstock  \n",
       "331  chueefadfirn-e  "
      ]
     },
     "execution_count": 1033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfll[pdfll['Names'].str.contains('chüef', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A dictionary with links from FoG to Mauro's database (names in FoG to full names, short names and IDs in Mauro's DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = {\n",
    "    'A NEUVE GL. L\\'':(['A NEUVE GLACIER DE L\\'-S','A NEUVE GLACIER DE L\\'-N'],['a neuve g de l\\'-s','a neuve g de l\\'-n'],['B85/07','B85/08'],True), # no area in FoG\n",
    "    'ADLER':('ADLERGLETSCHER (Teilgl. von B56/03)','adlerg','B56/14n', True),  # no area in FoG, but quite obvious\n",
    "    'ALBIGNA':('ALBIGNA VADREC D\\' (Nr. 116)','albigna vadrec d\\'', 'C84/16', True),  # ok, error in area in pdb  \n",
    "    'ALLALIN':('Allalingletscher* (Teilgl. von B52/66n)','allaling', 'B52/29', True), #ok area 9.68/9.17\n",
    "    'ALPETLI(KANDER)':('KANDERFIRN (Teilgl. von A55B/29n; Nr. 109)','kanderfirn','A55B/13',True),  # ok area 14/12\n",
    "    'ALTELS':(['Altels-S','Altels-NW','Altels-SE'],['altels-s','altels-nw','altels-se'],['A55C/04','A55C/03','A55C/18n'],True),     # no area in FoG \n",
    "    'AMMERTEN':(['Ammerten-W','AMMERTEN-E (Nr.111)'],['ammerteng-w','ammerteng-e'],['A55F/07n','A55F/01'],True),   # ok area 1.89/(0.55+0.22)\n",
    "    'AROLLA (BAS)':('MONT COLLON GLACIER DU (Teilgl. von B73/32n)','mont collon g du','B73/14',True),  # no equivalent in Mauro's DB (is included in Glacier du Mont Collon B73/14)\n",
    "    'BALMHORN':('BALMHORNGLETSCHER (Teilgl. von A55B/42n)','balmhorng','A55B/18',True),  # ok (area: 1.7/1.9)\n",
    "    'BASODINO':('BASODINO GH. DEL (Nr. 104)','basodino gh. del','C14/10',True),  # area bigger in Mauro's DB, even for only BASODINO GH. DEL (Nr. 104) (1.84/1.89). What to do with basodino-N and basodino-NW?\n",
    "    'BELLA TOLA':('BELLA TOLA GLETSCHER (Nr. 21)','bella tola g','B61/02',True),  # ok even though areas 0.31/0.07\n",
    "    'BIDER':('BIDERGLETSCHER','biderg','B53/08',True),  # ok (no area in FoG, but unique)\n",
    "    'BIFERTEN':('BIFERTENFIRN (Nr. 77)','bifertenfirn','A50I/12',True),  # ok (area: 2.86/2.5)\n",
    "    'BIRCH':('BIRCHGLETSCHER','birchg','B32/06',True),   # ok even though area 0.54/0.22\n",
    "    'BIS':('BISGLETSCHER (Nr. 107)','bisg','B58/08',True),    # ok even though area 4.79/3.82\n",
    "    'BLUEMLISALP':('BLÜMLISALPGLETSCHER (Nr. 64)','bluemlisalpg','A55B/02',True), # ok due to lat/lon area 2.22/2.98\n",
    "    'BODMER':('BODMER','bodmerg','C02/02',True),   # Link should be okay but area 0.64/0.32\n",
    "    'BOVEYRE':('BOVEIRE GLACIER DE (Nr. 41)','boveire g de','B84/04',True),  # ok (area 1.99/1.62)\n",
    "    'BREITHORN':('BREITHORNGLETSCHER','breithorng','A54M/19',True),   # Wetterlückengletscher (not in FoG) is added and oberer breithorngletscher becomes separate, no area/length in FoG for BREITHORN\n",
    "    'BRENEY':('BRENAY GLACIER DU (Nr. 36)','brenay g du','B82/19',True),   # ok areas 9.8/7.1\n",
    "    'BRESCIANA':('BRESCIANA VADRECC DI (Nr. 103)','bresciana vadrecc di','C44/02',True),  # ok even though area 0.94/0.48\n",
    "    'BRUNEGG':('BRUNEGGGLETSCHER (Teilgl. von B60/09; Nr. 20)','bruneggg','B60/20n',True),  # ok areas 6.1/5.5\n",
    "    'BRUNNI':('BRUNNIFIRN (Nr. 72)','brunnifirn','A51D/15',True),  # ok areas 2.99/2.31\n",
    "    'CALDERAS':('CALDERAS VADRET (Nr. 95)','calderas v','E35/17',True),   # ok even though areas 1.2/0.66\n",
    "    'CAMBRENA':('Cambrena Vadret dal (Teilgl. von C93/09)','cambrena v dal','C93/11n',True),  # ok area 1.77/1.26; Cambrena-E* (Teilgl. von C93/09) C93/08 excluded due to FoG lat/lon lying upstream \n",
    "    'CAVAGNOLI':('CAVAGNÖÖ GH. DEL (Nr. 119)','cavagnoeoe gh. del','C14/17',True), # ok due to lat/lon area 1.32/0.44 (ok as compared with SGI1973)\n",
    "    'CHEILLON':('CHEILON GLACIER DE (Nr. 29)','cheilon g de','B74/08',True), # okay even though area 4.73/3.6. Spelling?\n",
    "    'CLARIDENFIRN':(['CLARIDEN FIRN-II','CLARIDEN FIRN-IV*','CLARIDEN FIRN-I','CLARIDEN FIRN-I (Spitzalpelifirn)*','CLARIDEN FIRN-III*'],['clariden firn-ii','clariden firn-iv','clariden firn-i','clariden firn-iii'],['A50I/19','A50I/20','A50I/23n','A50I/24n'],True),  # area in FoG-D:5.12, but consistent over time even though volume changes!?\n",
    "    'CORBASSIERE':('Corbassière (Teilgl. von B83/03)*','corbassiere','B83/15n',True),  # ok. unclear if also Combin de Corbassière-E (Teilgl. von B83/03)* is meant (area: 0.4km2), but separated by ridge\n",
    "    'CORNO':('CORNO GH. DEL (Nr. 120)','corno gh. del','C34/01',True),  # ok even though area 0.27/0.1\n",
    "    'CROSLINA':('CROSLINA GRANDE GH. DI (Nr. 121)','croslina grande gh. di','C32/02',True), # ok even though area 0.47/0.11 (lat/lon!)\n",
    "    'DAMMA':('DAMMAGLETSCHER (Nr. 70)','dammag','A51F/10',True),  # ok even though area 6.32/4.24\n",
    "    'DOLENT GL. DU':('DOLENT GLACIER DU','dolent g du','B85/04',True),  # ok even though noe area given in FoG\n",
    "    'DUNGEL':('TUNGELGLETSCHER (Teilgl. von A56D/09n, Nr. 112)','tungelg','A56D/01',True),  #ok area 1.2/0.93\n",
    "    'EIGER':('EIGERGLETSCHER (Nr. 59)','eigerg','A54M/03',True),   # ok area 2.27/1.53\n",
    "    'EIGER (WEST)':('Eiger Südwestgrat*','eiger suedwestgrat','A54M/02',True),  # unclear, possibly  A54M/02\n",
    "    'EN DARREY':('EN DARREY GLACIER DE L\\' (Nr. 30)','en darrey g de l\\'','B74/11',True), #ok (areas 1.86/1.28)\n",
    "    'FEE NORTH':(['FEEGLETSCHER-S-I','FEEGLETSCHER-S-II','Feegletscher-N-I (Alphubel)* (Teilgl. von B53/16n)','Feegletscher-N-I (Täschhorn)* (Teilgl. von B53/16n)','Feegletscher-N-I (Dom)* (Teilgl. von B53/16n)','FEEGLETSCHER-N-II',],['feeg-s-i','feeg-s-ii','feeg-n-i','feeg-n-i','feeg-n-i','feeg-n-ii'],['B53/14n','B53/15n','B53/17n','B53/18n','B53/19n','B53/20n'],True),  # Feechopf-W* B55/17 ???\n",
    "    'FERPECLE':('FERPÈCLE GLACIER DE (Nr. 25)','ferpecle g de','B72/11',True),  # ok areas 9.79/9.0\n",
    "    'FIESCHER':('FIESCHERGLETSCHER VS (Teilgl. von B40/14n, Nr. 4)','fiescherg vs','B40/07',True), # ok area 33.06/29.48\n",
    "    'FINDELEN':('Findelengletscher * (Teilgl. von B56/03)','findeleng','B56/16n',True),  # ok even though area 19/14\n",
    "    'FIRNALPELI':(['FIRNALPELIGLETSCHER-E (Nr. 75)','FIRNALPELIFIRN'],['firnalpelig-e','firnalpelifirn'],['A51H/13','A51H/23n'],True),  # FoG lat/lon unclear; must be this combination due to elevation extent\n",
    "    'FORNO':('FORNO VADREC DEL (Nr. 102)','forno vadrec del','C83/12',True), # ok area 8.7/5.3; NICHT Ofenhorn-W* (lat/lon!)\n",
    "    'GAMCHI':('GAMCHIGLETSCHER (Nr. 61)','gamchig','A55A/04',True),  # ok area (1.73/1.23)\n",
    "    'GAULI':('GAULIGLETSCHER (Teilgl. von A54I/19n) Nr. 52','gaulig','A54I/05',True),  # ok (area 13.7/11.4)\n",
    "    'GELTEN':('GELTENGLETSCHER-W','gelteng-w','A56D/05',True),  # ok should receive the length changes from \"GELTEN\" entry\n",
    "    'GIETRO':('GIETRO GLACIER DU (Nr. 37)','gietro g du','B82/14',True),  # ok (area 5.54/5.16)\n",
    "    'GLAERNISCH':('GLÄRNISCHFIRN (Nr. 80)','glaernischfirn','A50K/04',True), # ok (area 2.09/1.41)\n",
    "    'GORNER':('GRENZGLETSCHER (Teilgl. von B56/07)','grenzg','B56/22n',True),  # problem: gorner not in Mauro's DB => it's named as \"Grenz\" there\n",
    "    'GRAND DESERT':('GRAND DESERT (Nendaz*) (Nr. 31)','grand desert','B75/06',True),  # ok area 1.85/1.06\n",
    "    'GRAND PLAN NEVE':('PLAN NEVE-E (Nr. 45)','plan neve-e','B17/03',True), # is plan neve-e (area 0.12/0.18) due to lat/lon of FoG point, elevation confirms\n",
    "    'GRIES':('GRIESGLETSCHER (Nr. 3)','griesg','B45/04',True),  # ok (area 4.83/4.78)\n",
    "    'GRIESS(KLAUSEN)':(['GRIESSFIRN-I (Nr. 74)','Griessfirn-II*'],['griessfirn-i','griessfirn-ii'],['A51C/02','A51C/01'],True),  # probably more:   and  \n",
    "    'GRIESSEN(OBWA.)':('GRIESSENFIRN','GRIESSENFIRN','A51H/02',True),  # ok (area 1.27/0.86)\n",
    "    'GRIESSERNU':('GRIESSERNU GLETSCHER','griessernu g','C02/06',True), # ok even though no area in FoG\n",
    "    'GROSSER ALETSCH':('GROSSER ALETSCH GLETSCHER (Teilgl. von B36/49n) Nr. 5','grosser aletsch g','B36/26',True), # ok (area 81.3/78.3)\n",
    "    'GRUBEN':(['GRÜEBUGLETSCHER-N-II (Teilgl. von B51/17n)','GRÜEBUGLETSCHER-S (Teilgl. von B51/17n)','GRÜEBUGLETSCHER-N-I  (Teilgl. von B51/17n)'],['grueebug-n-ii','grueebug-s','grueebug-n-i'],['B51/04','B51/05','B51/16n'],True), # ok area (1.32/(0.18+0.94+0.08)), NAME SHOULD  BE CHANGED IN FoG\n",
    "    'GUTZ':('GUTZGLETSCHER','gutzg','A54L/02',True),  # ok even though no area in FoG\n",
    "    'HANGENDE':('HANGENDE GLETSCHER','hangende g', 'B52/27',True), # ok due to lat/lon\n",
    "    'HINDRE SCHMADRI':('HINDRE SCHMADRIGLETSCHER','hindre schmadrig','A54M/16',True),  # ok no area in FoG\n",
    "    'HOHLAUB':(['Hohlaubgrat-E* (Teilgl. von B52/67n)','Hohlaub Gletscher* (Teilgl. von B52/67n)'],['hohlaubgrat-e','hohlaub g'],['B52/31','B52/32'],True), # both  and \n",
    "    'HOMATTU':(['HOMATTUGLETSCHER-II','HOMATTUGLETSCHER-I'],['homattug-ii','homattug-i'],['B47/05','C04/01'],True), # ok no area in FoG  \n",
    "    'HUEFI':('HÜFIFIRN (Nr. 73)','huefifirn','A51D/10',True),  # ok (area 13.73/12.72)\n",
    "    'KALTWASSER':('CHALTWASSERGLETSCHER (Nr. 7)','chaltwasserg','B47/04',True),  # ok (areas 18.5/1.49)\n",
    "    'KEHLEN':('CHELENGLETSCHER (Totalgl.; Nr. 68)','cheleng','A51F/15',True),  # ok even though area 1.73/3.15\n",
    "    'KESSJEN':('CHESSJENGLETSCHER-E (Nr. 12)','chessjeng-e','B52/33',True), #ok (areas 0.19/0.19) there is now chessjengl.-w!\n",
    "    'LAEMMERN (WILDSTRUBEL)':('WILDSTRUBELGLETSCHER (Teilgl. von A55C/24n) Nr. 63','wildstrubelg','A55C/13',True), # ok even though area 3.15/2.34\n",
    "    'LANG':('Langgletscher (Totalgl.; Nr. 18)','langg','B31/19n',True),  # ok areas 10.03/8.26\n",
    "    'LAVAZ':(['LAVAZ GLATSCHER DA (Nr. 82)','Lavaz-W*'],['lavaz glatscher da','lavaz-w'],['A14F/15','A14F/16'],True),  # ok area 1-76/(0.7+0.09)\n",
    "    'LENTA':('LÄNTAGLETSCHER (Nr. 84)','laentag','A14D/17',True),  # ok area 1.4/0.81\n",
    "    'LIMMERN':('LIMMERNFIRN (Nr. 78)','limmernfirn','A50I/06',True), # ok (area 2.41/1.89)\n",
    "    'LISCHANA':(['TRIAZZA VADRET DA'],['triazza v da'],['E02/05'],True),  # vadret da triazza is one of the two remnants (one is no longer mapped); LEAVE BRACKETS IN ORDER TO ASSIGN PARENT ID CORRECTLY!\n",
    "    'MAIGHELS EAST BRANCH':('MAIGHELS GLATSCHER DA-E','maighels glatscher da-e','A14I/04',True),  # ok but no area in FoG\n",
    "    'MAIGHELS WEST BRANCH':('MAIGHELS GLATSCHER DA-W','maighels glatscher da-w','A14I/05',True),  # ok but no area in FoG\n",
    "    'MARTINETS':('MARTINETS GLACIER DES (Nr. 46)','martinets g des','B17/08',True), # ok area 0.59/0.36\n",
    "    'MINSTIGER':('MINSTIGERGLETSCHER','minstigerg','B41/07',True),  # ok areas 3.09/2.25\n",
    "    'MITTELALETSCH':('MITTELALETSCHGLETSCHER (Teilgl. von B36/49n) Nr. 106','mittelaletschg','B36/21',True), # ok area 8.5/6.8\n",
    "    'MOIRY':('MOIRY GLACIER DE (Nr. 24)','moiry g de','B64/02',True), # ok area 6.11/4.89\n",
    "    'MOMING':('MOMING GLACIER DE (Nr. 23)','moming g de','B62/10',True),  # ok , maybe also Pointe Nord de Moming-SE* and Blanc de Moming-W*\n",
    "    'MONT DURAND':('MONT DURAND GLACIER DU (Nr. 35)','mont durand g du','B82/36',True),  # ok area 7.59/6.09\n",
    "    'MONT FORT (ZINAL)':(['PETIT M. FORT GLACIER DU','M. FORT GLACIER DU','Mont Fort-E*'],['petit m. fort g du','m. fort g du','mont fort-e'],['B75/07','B75/09','B75/16n'],True),  # not clear, probably PETIT M. FORT GLACIER DU (B75/07), but area is still too low\n",
    "    'MONT MINE':('MONT MINÉ GLACIER DU (Nr. 26)','mont mine g du','B72/15',True), # ok areas 10.3/9.9\n",
    "    'MONTO MORO GL.':('Monte Moro-W*','monte moro-w','B52/21',True),  # only a remnant obviously\n",
    "    'MORTERATSCH':('MORTERATSCH VADRET DA (Totalgl.; Nr. 94)','morteratsch v da','E22/03',True), # ok areas 17/15\n",
    "    'MURTEL':('MURTEL VADRET DAL','murtel v dal', 'E23/16',True),  # ok, NOT E24/04!!! \n",
    "    'MUTT':('MUTTGLETSCHER (Nr. 2)','muttg','B44/03',True), # ok, area 0.57/0.36\n",
    "    'MUTTEN':('Muttengletscher* (Teilgl. von A51E/23)','mutteng','A51E/56n',True), #ok, no areas in FoG\n",
    "    'OB.GRINDELWALD':('OBERER GRINDELWALDGLETSCHER (Nr. 57)','oberer grindelwaldg','A54L/04',True), # ok areas 10.07/8.41\n",
    "    'OBERAAR':('OBERAARGLETSCHER (Teilgl. von A54G/35n) Nr. 50','oberaarg','A54G/03',True), # ok areas 5.23/4.10\n",
    "    'OBERALETSCH':('OBERALETSCH GLETSCHER (Totalgl.; Nr. 6)','oberaletsch g','B36/01',True),  # ok areas 21/17\n",
    "    'OFENTAL':('OFENTAL GLETSCHER (Nr. 9)','ofental g','B52/17',True),  #ok even though areas 0.4/0.04...possibly one remnant missing in Mauro's DB (see swisstopo)\n",
    "    'OTEMMA':('Otemma (Teilgl. von B82/27)*','otemma','B82/51n',True),  # ok areas 16.55/12.59\n",
    "    'PALUE':('Palü Vadret da (Teilgl. von C93/04)','palue v da','C93/10n',True),  # ok areas 6.62/5.26\n",
    "    'PANEYROSSE':('PANEIROSSE GLACIER DE (Nr. 44)','paneirosse g de','B17/02',True),  # ok areas 0.45/0.3\n",
    "    'PARADIES':('PARADIESGLETSCHER (Nr. 86)','PARADIESGLETSCHER (Nr. 86)','A13N/06',True),  # ok 4.6/1.8\n",
    "    'PARADISINO (CAMPO)':('CAMP VEDREIT DA (Nr. 101)','camp vedreit da','C95/01',True),  # ok area 0.55/0.26\n",
    "    'PIERREDAR':('PIERREDAR GLACIER DE (Nr. 49)','pierredar g de','B16/05',True), # ok areas 0.67/0.3\n",
    "    'PIZOL':('PIZOLGLETSCHER (Nr. 81)','pizolg','A50D/01',True), # ok areas 0.32/0.08\n",
    "    'PLAINE MORTE':(['GLACIER DE LA PLAINE MORTE (Nr. 65)','PLAINE MORTE-W GLACIER DE LA','PLAINE MORTE-E GLACIER DE LA'],['g de la plaine morte','plaine morte-w g de la','plaine morte-e g de la'],['A55F/03','B23/09n','B24/04n'],True), # no area in FoG\n",
    "    'PLATTALVA':('GRIESSFIRN-N (Plattalva, Nr. 114)','griessfirn-n','A50I/07',True),  # ok area 0.71/0.33\n",
    "    'PORCHABELLA':('PORCHABELLA VADRET DA (Nr. 88)','porchabella v da','A12E/04',True),  # ok area 2.59/1.67\n",
    "    'PRAPIO':('PRAPIO GLACIER DU (Nr. 48)','prapio g du','B16/03',True),   # ok area 0.36/0.21\n",
    "    'PUNTEGLIAS':('Bündner Tödi*','buendner toedi','A14M/08',True),  #  sounds strange but ok area 0.93/0.67\n",
    "    'RHONE':('Rhonegletscher* (Teilgl. von B43/03)','rhoneg','B43/12n',True),  # ok areas 15.8/15.31\n",
    "    'RIED':('RIEDGLETSCHER (Nr. 17)','riedg','B54/03',True),  # ok areas 8.26/7.31\n",
    "    'ROSEG':('ROSEG VADRET DA (Nr. 92)','roseg v da','E23/11',True),  # ok areas 8.71/6.81\n",
    "    'ROSENLAUI':('ROSENLAUIGLETSCHER (Nr. 56)','rosenlauig','A54J/02',True),  # ok areas 5.9/5.4\n",
    "    'ROSSBODEN':('ROSSBODEGLETSCHER (Nr. 105)','rossbodeng','C02/04',True),  # ok areas 1.89/1.18\n",
    "    'ROTFIRN NORD':('Schattmigstock* (Rotfirn-N, Nr. 69)','schattmigstock','A51F/13',True),  #  ok area 1.21/0.91\n",
    "    'ROTTAL':('ROTTALGLETSCHER-NW (Teilgl. von B52/02)','rottalg-nw','B52/37n',True),  #  ok no area in FoG\n",
    "    'SALEINA':('Saleina* (Teilgl. von B85/16)','saleina','B85/29n',True),  # is , but area is too high (6.54) compared to FoG (5.03)\n",
    "    'SANKT ANNA':('ST. ANNAFIRN (Nr. 67)','st. annafirn','A51E/12',True),  # ok even though areas 0.41/0.22 (might be debris problem)\n",
    "    'SARDONA':('Sardonagletscher-II*','sardonag-ii','A15B/06n',True),  # should be Sardonagletscher-II*, but area is too high (0.45, FoG only 0.38)\n",
    "    'SCALETTA':('SCALETTAGLETSCHER (Nr. 115)','scalettag','A12D/03',True),  # ok even though area 0.66/0.21 (debris?)\n",
    "    'SCHOENBUEHL GL.':(['SCHÖNBÜHLGLETSCHER-SE','SCHÖNBÜHLGLETSCHER-NW'],['schoenbuehlg-se','schoenbuehlg-nw'],['B36/31','B36/56n'],True),  # FoG-D area (1957):1.43/(0.57+0.43)\n",
    "    'SCHWARZ':('SCHWARZGLETSCHER (Nr. 62)','schwarzg','A55C/05',True),  #  okay areas 1.6/1.09\n",
    "    'SCHWARZBACH':('SCHWARZBACHFIRN','schwarzbachfirn','A51E/08',True),  #  okay (not area in FoG)\n",
    "    'SCHWARZBERG':('Schwarzberggletscher* (Teilgl. von B52/24)','schwarzbergg','B52/63n',True),  #  ok area 5.17/5.33\n",
    "    'SESVENNA':('Sesvenna Vadret da-E (Teilgl. von E03/04)','sesvenna v da-e','E03/11n',True),  #  ok area 0.67/0.33\n",
    "    'SEEWJINEN':('SEEWJINEN GLETSCHER','seewjinen g','B52/22',True),  # ok no area in FoG\n",
    "    'SEX ROUGE':('SEX ROUGE GLACIER DU (Nr. 47)','sex rouge g du','B16/01',True), # ok even though area 0.72/0.27\n",
    "    'SILLERN':('SILLERE GLETSCHER','sillere g','A55B/11',True),  #  ok (no area in FoG)\n",
    "    'SILVRETTA':('SILVRETTAGLETSCHER (Nr. 90)','silvrettag','A10G/05',True),  # ok areas 2.74/2.67\n",
    "    'SIRWOLTE':('Griessernuhorn-N*','griessernuhorn-n','C03/04',True),  #should be Griessernuhorn-N* (c03/04) => NAME CHANGE IN FoG\n",
    "    'STEIN':('STEINGLETSCHER (Nr. 53)','steing','B47/01',True),  # ok even though area in Mauro's DB (5.68) slightly bigger than in FoG (5.6)\n",
    "    'STEINLIMMI':('STEINLIMIGLETSCHER (Nr. 54)','steinlimig','A54E/13',True),  # ok areas 2.21/1.59\n",
    "    'SULZ':('HINTERSULZFIRN (Nr. 79)','hintersulzfirn','A50I/02',True),  #  must be HINTERSULZFIRN (Nr. 79), A50I/02,  (lat/lon), but area is bigger (0.26) than in FoG (0.2)\n",
    "    'SURETTA':(['SURETTAGLETSCHER-E (Piz Por*)','SURETTAGLETSCHER-W (Hauptgl., Nr. 87)'],['surettag-e','surettag-w'],['A13I/01','A13I/02'],True), # must be ,  and maybe also Suretta Lückli*. FoG point unclear\n",
    "    'TIATSCHA':('TIATSCHA VADRET (La Cudera, Nr. 96)','tiatscha v','E50/07',True), # okay areas 2.11/1.82\n",
    "    'TIEFEN':('TIEFENGLETSCHER (Nr. 66)','tiefeng','A51E/37', True), # ok even though area 3.17/1.99\n",
    "    'TOURNELON BLANCE':('Tournelon Blanc-SE*','Tournelon Blanc-E*','Tournelon Blanc-NE*','Col du Tournelon Blanc*',['tournelon blanc-se','tournelon blanc-e','tournelon blanc-ne','col du tournelon blanc'],['B82/42','B82/43','B82/44','B82/53n'],True),  # defined as given polygons as only special event in FoG \n",
    "    'TRIENT':('TRIENT GLACIER DU (Nr. 43)','trient g du','B90/02',True),  # ok area 6.58/5.82\n",
    "    'TRIEST GL.':('DRIESTGLETSCHER','driestg','B36/17',True),  # ok no area in FoG\n",
    "    'TRIFT (GADMEN)':('TRIFTGLETSCHER (Nr. 55)','triftg','A54E/24',True),  # ok area 15.33/14.9\n",
    "    'TSANFLEURON':('TSANFLEURON GLACIER DE (Nr. 33)','tsanfleuron g de','B22/01',True),  # ok area 3.78/2.64\n",
    "    'TSCHIERVA':(['TSCHIERVA VADRETTIN DA','TSCHIERVA VADRET DA (Nr. 93)'],['tschierva vtin da','tschierva v da'],['E23/04','E23/06'],True),  # area is 6.83/(0.4+5.81); FoG lat/lon suggests to include also the vadrettin\n",
    "    'TSCHINGEL':(['TSCHINGELFIRN (Nr. 60)','Tschingelspitz-S*','Tschingelgrat-S*'],['tschingelfirn','tschingelspitz-s','tschingelgrat-s'],['A54M/21','A54M/51n','A54M/52n'],True),  # area 6.18/(5.22+0.01+0.006)\n",
    "    'TSEUDET':('TSEUDET GLACIER DE (Nr. 40)','tseudet g de','B84/17',True),  # ok area 1.76/1.43\n",
    "    'TSIDJIORE NOUVE':('TSIJIORE NOUVE GLACIER DE (Nr. 28)','tsijiore nouve g de','B73/16',True), # ok even though area 3.12/2.72\n",
    "    'TURTMANN (WEST)':('TURTMANNGLETSCHER (Teilgl. von B60/09)','turtmanng','B60/21n',True),  # chaos in FoG: sometimes brunegggletscher is included in turtmanngletscher (see state table). TURTMANNGLETSCHER (Teilgl. von B60/09) is only about half (5.5) of turtmann-w in FoG (11km2)\n",
    "    'UNT.GRINDELWALD':(['OBERS ISCHMEER (Teilgl. von A54L/19)','FIESCHERGLETSCHER BE (Teilgl. von A54L/19)'],['obers ischmeer','fiescherg be'],['A54L/31n','A54L/36n'],True),  # leave Unt. Grindelw. and make it parent\n",
    "    'UNTERAAR':('UNTERAARGLETSCHER (Teilgl.von A54G/50n) Nr. 51','unteraarg','A54G/11',True), # ok area 22.7/22.5\n",
    "    'VAL TORTA':('VALTORTA VADRET','valtorta v','E46/06',True),  # ok area 0.17/0.06\n",
    "    'VALLEGGIA':('VALLEGGIA GH. DI (Nr. 117)','valleggia gh. di','C33/08',True),  # ok area 0.59/0.30\n",
    "    'VALSOREY':('Valsorey (Teilgl. von B84/15)*','valsorey','B84/27n',True),  #  ok area 2.34/1.9\n",
    "    'VERSTANKLA':('Verstanclagletscher (Teilgl. von A10G/08)','verstanclag','A10G/24n',True), #ok area 1.06/0.71\n",
    "    'VORAB':('VORAB GLATSCHER DIL (Nr. 85)','vorab glatscher dil','A14P/01',True), # ok area 2.51/1.22, could also be Vorabsattel-W* (but drain ins other valley)\n",
    "    'VORDRE SCHMADRI':('VORDRE SCHMADRIGLETSCHER','vordre schmadrig','A54M/15',True),  # ok no area in FoG\n",
    "    'WALLENBUR':('WALLENBURFIRN (Nr. 71)','wallenburf','A51F/24',True), # ok area 1.7/1.41\n",
    "    'WANNENHORN GL. N':('WANNENHORNGLETSCHER-NW (Teilgl. von B36/57n)','wannenhorng-nw','B36/32',True), # must be this one due to FoG lat/lon\n",
    "    'WANNENHORN GL. S':('WANNENHORNGLETSCHER-SE (Teilgl. von B36/57n)','wannenhorng-se','B36/33',True), # must be this one due to FoG lat/lon\n",
    "    'WITENWASSEREN':('WITENWASSERENGLETSCHER','witenwassereng','A51E/20',True), # no FoG area given....(could also include Witenwasseren-W*, but drains in another valley)\n",
    "    'ZENBAECHEN GL.':('ZENBAECHENGLETSCHER','zenbaecheng','B36/18',True), # no FoG area given\n",
    "    'ZINAL':('ZINAL GLACIER DE (Nr. 22)','zinal g de','B63/05',True),  # ok area 16/13.3 \n",
    "    'ZMUTT':('ZMUTTGLETSCHER (Nr. 15)','zmuttg','B57/05',True),  # ok area 17.4/13.7    \n",
    "}\n",
    "\n",
    "# removed:\n",
    "# 'WANNENHORN GL.':('','','',False),  # is only parent glacier, parent IDs for S/N already present, so can be deleted from dict\n",
    "# 'TAELLIBODEN':('','','',False),  # no longer digitized in Mauro's inventory => seems to be totally disappeared on orthophoto\n",
    "# 'RAETZLI (PLAINE MORTE)':('GLACIER DE LA PLAINE MORTE (Nr. 65)','g de la plaine morte','A55F/03',True),  # more or less the same as PLAINE MORTE, min_elevation in PDB except for confusing entry by Huss 2011\n",
    "# 'FLUCHTHORN GL.':('','','', False), # should be Fluchthorn-NE* B52/26 and maybe also Fluchthorn-E* B52/25 (area 0.37/(0.26+0.01)); problem is hangender ferner inbetween; is taken out due to Michi's suggestion to keep old glacier (unknown which it is and include a duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This prints the 'False' cases\n",
    "for key,val in links.items():\n",
    "    if not val[-1]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin to establish new dataset containing the columns from the CHANGE file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Determine which glaciers glaciers are already in FoG, which are problematic and which need a new ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n",
      "0\n",
      "187\n",
      "1284\n"
     ]
    }
   ],
   "source": [
    "take_over_id = {}                                    # those glaciers that can take over a FoG ID\n",
    "problems = {}                                        # those glaciers where it is unclear whether they can take over an ID \n",
    "new_id = pdfll.Glacier_name_SGI2010.values.tolist()  # those glaciers from Mauro's DB that need a new ID (all - (take_over_id + problems))\n",
    "\n",
    "print(len(new_id))\n",
    "for key,value in links.items():\n",
    "    # assign take over/problems\n",
    "    if value[-1] == True:\n",
    "        take_over_id[key] = value\n",
    "    else:\n",
    "        problems[key] = value\n",
    "        \n",
    "    # check which still need a new ID\n",
    "    if value[-1] == True: \n",
    "        if isinstance(value[-2], str):\n",
    "            new_id.remove(value[-2])\n",
    "        elif isinstance(value[-2], list):\n",
    "            pass\n",
    "            #for element in value[-2]:\n",
    "                #new_id.remove(element)\n",
    "        else:\n",
    "            raise ValueError('%s neither list nor string' % value[-2])\n",
    "        \n",
    "        \n",
    "print(sum([len(problems[key][-2]) for key,value in problems.items()])) # sum of all SGI2010 short names => should be zero for problems\n",
    "print(sum([len(take_over_id[key][-2]) if isinstance(take_over_id[key][-2],list) else 1 for key,value in take_over_id.items()])) # # sum of all SGI2010 short names\n",
    "print(len(new_id)) # sum of all SGI2010 short names that need a new ID in FoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "print(len(pdfll))#-len(take_over_id))\n",
    "print(len(take_over_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTENTION: As long as not all problems are solved, we generate too many new IDs!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some new raw DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pda = pd.DataFrame(columns=pda.columns.values)\n",
    "new_pdb = pd.DataFrame(columns=pdb.columns.values)\n",
    "new_pdd = pd.DataFrame(columns=pdd.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some new arbitrary IDs, beginning at given number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin_new_id = 4585  # where to start with assigning new WGMS IDs\n",
    "new_id_range = list(range(begin_new_id, begin_new_id+len(pdf)+1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some correction rules to transform Mauro's names to FoG names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_adjust_FoG = {'gletscher':'', 'ferner':'','gh.':'ghiacciaio', 'gl.':'','teilgl. von':'part of', 'teil ':'part ', ' von ':' of ', '*':'', 'nr.':'no.', 'haupt':'main', 'zus\\'gesetzt':'combined', 'nur fläche':'only area', 'nur':'only', 'flaeche':'area', 'sammler':'group of glacierets', 'ost':'e','nord':'n','ä':'ae', 'ö':'oe', 'ü':'ue', 'é':'e', 'à':'a', 'è':'e', 'ô':'o', 'ß':'ss'} # 'firn':'',\n",
    "hot_list = ['glacier', 'vadret', 'ghiacciaio', 'vedretta', 'glatscher', 'vadret', 'vadrec.'] # vadrec. is important as also 'vadrecc' appears (regex search) \n",
    "special_names ={'GLACIER DE LA PLAINE MORTE (Nr. 65)':'PLAINE MORTE, GLACIER DE LA',\n",
    "             'PLAINE MORTE-W GLACIER DE LA':'PLAINE MORTE GLACIER DE LA-W',\n",
    "             'PLAINE MORTE-E GLACIER DE LA':'PLAINE MORTE GLACIER DE LA-E'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_pda = new_pda[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'RIVER_BASIN', 'FREE_POSITION',\n",
    "                                   'LOCAL_CODE', 'LOCAL_PSFG', 'GEN_LOCATION', 'SPEC_LOCATION', 'LATITUDE', 'LONGITUDE', \n",
    "                                   'PRIM_CLASSIFIC', 'FORM', 'FRONTAL_CHARS', 'EXPOS_ACC_AREA', 'EXPOS_ABL_AREA', \n",
    "                                   'PARENT_GLACIER', 'REMARKS']]#, 'GEO-REGION_CODE', 'GEO-SUBREGION_CODE', 'AREA']]\n",
    "\n",
    "new_pdb = new_pdb[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'HIGHEST_ELEVATION','MEDIAN_ELEVATION', \n",
    "                                   'LOWEST_ELEVATION', 'ELEVATION_UNC', 'LENGTH', 'LENGTH_UNC', 'AREA', 'AREA_UNC', \n",
    "                                   'SURVEY_DATE', 'SURVEY_PLATFORM_METHOD', 'INVESTIGATOR', 'SPONS_AGENCY', \n",
    "                                   'REFERENCE', 'REMARKS']]\n",
    "\n",
    "new_pdd = new_pdd[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'LOWER_BOUND','UPPER_BOUND', \n",
    "                                   'AREA_SURVEY_YEAR', 'AREA_CHANGE', 'AREA_CHANGE_UNC', 'THICKNESS_CHG', \n",
    "                                   'THICKNESS_CHG_UNC', 'VOLUME_CHANGE', 'VOLUME_CHANGE_UNC', 'SURVEY_DATE', \n",
    "                                   'SD_PLATFORM_METHOD', 'REFERENCE_DATE', 'RD_PLATFORM_METHOD', \n",
    "                                   'INVESTIGATOR', 'SPONS_AGENCY', 'REFERENCE', 'REMARKS']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def name_to_FoG(name, replace_dict, hot_list, special_names):\n",
    "    \n",
    "    # check if it is a very special name\n",
    "    if name in special_names.keys():\n",
    "        return special_names[name]\n",
    "    \n",
    "    # to make it easier comparable\n",
    "    name = name.lower()\n",
    "    \n",
    "    # replace some predefined stuff\n",
    "    for key in replace_dict.keys():\n",
    "        #key_regex = re.compile(key)\n",
    "        #if 'teil' in name:\n",
    "        #    print(name)\n",
    "        if key in name:\n",
    "        #if re.match(key_regex, name):\n",
    "            name = name.replace(key, replace_dict[key])\n",
    "        #print(name)\n",
    "    \n",
    "    # replace the bracket stuff\n",
    "    #start = name.find('(')\n",
    "    #if start != -1:\n",
    "    #    name = name[0:start]\n",
    "    #name = name.replace('*', '')\n",
    "    #name = name.strip()\n",
    "    \n",
    "    # if the name is already sorted in the desired way (e.g. 'lai blau glatscher dil'), insert a comma as specified by Michi\n",
    "    \n",
    "    \n",
    "    # reorder the words\n",
    "    splitname = name.split(' ')\n",
    "    if len(splitname) >= 3:\n",
    "        for hotname in hot_list:\n",
    "            hotname_regex = re.compile(hotname)  # regex search due to \"vadrecc\" problem\n",
    "            if re.match(hotname_regex, name) and len(splitname)>1:\n",
    "                print(name, hotname,splitname)\n",
    "                try:\n",
    "                    resort_ix = splitname.index(hotname)\n",
    "                except:\n",
    "                    resort_ix = splitname.index(hotname_regex)\n",
    "                if resort_ix == 0: # e.g. \"glacier de BLA\"\n",
    "                    name = splitname[-1]+', '+' '.join(splitname[:-2])\n",
    "                    print(name)\n",
    "                elif resort_ix == 1: # e.g. \"BLA glacier de\"\n",
    "                    name = splitname[0]+', '+' '.join(splitname[1:])\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    return name.upper()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some constants\n",
    "POL_UNIT = 'CH'\n",
    "RGI_REGION = 'Central Europe'\n",
    "RGI_SUBREGION = 'Alps'\n",
    "MISS_VAL = 9999\n",
    "SD_PLATFORM_METHOD = 'aC'\n",
    "RD_PLATFORM_METHOD = 'aC'\n",
    "SD_METHOD = 'PL'\n",
    "RD_METHOD = 'M'\n",
    "REFERENCE = 'Fischer et al. (2014); Arctic, Antarctic and Alpine Research, 46(4), pp.933-945'\n",
    "AGENCY = 'Department of Geosciences, University of Fribourg, 1700 Fribourg, Switzerland'\n",
    "INVESTIGATOR = 'Fischer et al.'\n",
    "PUB_DATE = int(2016)\n",
    "LENGTH_UNC_FACTOR = 0.05   # actually 2-5%, but specification says \"maximum\" error\n",
    "# ELEV_UNC = 3.0   # vertical accuracy 1-3m for swissimage (see Fischer et al. 2014); not used as also digitizing error and terrain steepness plays a role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def area_unc(area):\n",
    "    AREA_UNC_FACTOR_S = 0.076  # for Small glaciers (<1km2)\n",
    "    AREA_UNC_FACTOR_M = 0.047  # for Medium glaciers (1-5km2)\n",
    "    AREA_UNC_FACTOR_L = 0.076  # for Large glaciers (>5km2)\n",
    "    \n",
    "    if area <1.:\n",
    "        area_uncert = area * AREA_UNC_FACTOR_S\n",
    "    elif 1. <= area <= 5.:\n",
    "        area_uncert = area * AREA_UNC_FACTOR_M\n",
    "    elif area > 5.:\n",
    "        area_uncert = area * AREA_UNC_FACTOR_L\n",
    "    return area_uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_entries_id_present(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, take_over_dict, new_ids):\n",
    "\n",
    "    for key,val in take_over_id.items():\n",
    "\n",
    "        # two new DFs for the different FoG files\n",
    "        glacier_pdd = pd.DataFrame(columns=new_pdd.columns.values)\n",
    "        glacier_pda = pd.DataFrame(columns=new_pda.columns.values)\n",
    "        glacier_pdb = pd.DataFrame(columns=new_pdb.columns.values)\n",
    "\n",
    "        # present WGMS ID\n",
    "        gid = pda[pda.NAME == key].WGMS_ID.values[0]\n",
    "\n",
    "        # Mauros glaciers entry: \n",
    "        if isinstance(val[-2], str): # if there is only one equivalent: fill only PDD and leave PDA as it is\n",
    "            mg = pdf[pdf.Code_SGI2010 == val[-2]]\n",
    "            mg_ll = pdfll[pdfll.Glacier_name_SGI2010 == val[-2]]\n",
    "\n",
    "            # set the REMARKS (added at the end)\n",
    "            REMARKS_pdd = ''\n",
    "            REMARKS_pdb = ''\n",
    "\n",
    "            if not mg.empty:\n",
    "                glacier_pdd.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                glacier_pdd.loc[gid, 'NAME'] = pda[pda.WGMS_ID == gid].NAME.iloc[0]\n",
    "                glacier_pdd.loc[gid, 'WGMS_ID'] = gid\n",
    "                glacier_pdd.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                glacier_pdd.loc[gid, 'LOWER_BOUND'] = MISS_VAL\n",
    "                glacier_pdd.loc[gid, 'UPPER_BOUND'] = MISS_VAL\n",
    "                glacier_pdd.loc[gid, 'AREA_SURVEY_YEAR'] = mg.area_t2_km2.iloc[0]\n",
    "                glacier_pdd.loc[gid, 'AREA_CHANGE'] = (mg.area_t2_km2.iloc[0] - mg.area_t1_km2.iloc[0]) * 1000  # *1000: unit difference (1000m2 and km2)\n",
    "                #glacier_pdd.loc[gid, 'AREA_CHANGE_UNC'] = round((area_unc(mg.area_t1_km2.iloc[0]) + area_unc(mg.area_t2_km2.iloc[0]))* 1000, 2)  # error is addition of both errors for t1 and t2 in worst case; *1000 for unit\n",
    "                glacier_pdd.loc[gid, 'THICKNESS_CHG'] = round(((mg.dvol_mio_m3_between_t1_and_t2.iloc[0] * 10**6) / ((mg.area_t2_km2.iloc[0] + mg.area_t1_km2.iloc[0]) * 0.5 * 10**6)) * 1000, -1) # *1000 for conversion from m thickness change to mm change\n",
    "                #glacier_pdd.loc[gid, 'THICKNESS_CHG_UNC'] = np.nan  # berechnen? AREA_UNC fehlt und der Fehler durch Mittelung\n",
    "                glacier_pdd.loc[gid, 'VOLUME_CHANGE'] = mg.dvol_mio_m3_between_t1_and_t2.iloc[0] *1000   # *1000: unit difference (1000m3 / 1000000m3)\n",
    "                glacier_pdd.loc[gid, 'VOLUME_CHANGE_UNC'] = round(mg.uncertainty_dvol_between_t1_and_t2_mio_m3.iloc[0]) # *1000:unit difference (1000m3 / 1000000m3)\n",
    "                glacier_pdd.loc[gid, 'SURVEY_DATE'] = int(mg.t2_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                glacier_pdd.loc[gid, 'SD_PLATFORM_METHOD'] = SD_PLATFORM_METHOD # must be determined\n",
    "                REMARKS_pdd = REMARKS_pdd + ' Survey date method: %s.' % SD_METHOD\n",
    "                glacier_pdd.loc[gid, 'REFERENCE_DATE'] = int(mg.t1_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                glacier_pdd.loc[gid, 'RD_PLATFORM_METHOD'] = RD_PLATFORM_METHOD   # must be determined\n",
    "                REMARKS_pdd = REMARKS_pdd + ' Reference date method: %s.' % RD_METHOD\n",
    "                #glacier_pdd.PUB_IN_FOG = PUB_DATE      # not needed in data submission form\n",
    "                glacier_pdd.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                glacier_pdd.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                glacier_pdd.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                REMARKS_pdd = REMARKS_pdd + ' ID SGI 1973: %s.' % mg.ID_SGI1973.iloc[0]\n",
    "                REMARKS_pdd = REMARKS_pdd + ' ID SGI 2010: %s.' % mg.Code_SGI2010.iloc[0]\n",
    "                # at the very end \n",
    "                glacier_pdd.loc[gid, 'REMARKS'] = REMARKS_pdd\n",
    "                \n",
    "                new_pdd = pd.concat([new_pdd, glacier_pdd], ignore_index=True)\n",
    "           \n",
    "                                                           \n",
    "                # fill PDB                                           \n",
    "                glacier_pdb.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                glacier_pdb.loc[gid, 'NAME'] = pda[pda.WGMS_ID == gid].NAME.iloc[0]\n",
    "                glacier_pdb.loc[gid, 'WGMS_ID'] = gid\n",
    "                glacier_pdb.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                glacier_pdb.loc[gid, 'HIGHEST_ELEVATION'] = mg_ll['max_elevation (masl)'].iloc[0]\n",
    "                glacier_pdb.loc[gid, 'MEDIAN_ELEVATION'] = mg_ll['median_elevation (masl)'].iloc[0]\n",
    "                glacier_pdb.loc[gid, 'LOWEST_ELEVATION'] = mg_ll['min_elevation (masl)'].iloc[0]\n",
    "                #glacier_pdb.loc[gid, 'ELEVATION_UNC'] = np.nan\n",
    "                glacier_pdb.loc[gid, 'LENGTH'] = mg_ll['length (km)'].iloc[0]\n",
    "                #glacier_pdb.loc[gid, 'LENGTH_UNC'] = round(mg_ll['length (km)'].iloc[0] * LENGTH_UNC_FACTOR, -1)  # round to next ten meters\n",
    "                glacier_pdb.loc[gid, 'AREA'] = mg_ll['area(km2)'].iloc[0]\n",
    "                #glacier_pdb.loc[gid, 'AREA_UNC'] = round(area_unc(mg.area_t1_km2.iloc[0]), 2)  # round to 0.01km2\n",
    "                glacier_pdb.loc[gid, 'SURVEY_DATE'] = mg_ll.year.iloc[0]\n",
    "                glacier_pdb.loc[gid, 'SURVEY_PLATFORM_METHOD'] = SD_PLATFORM_METHOD\n",
    "                REMARKS_pdb = REMARKS_pdb + ' Survey date method: %s.' % SD_METHOD\n",
    "                glacier_pdb.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                glacier_pdb.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                glacier_pdb.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                glacier_pdb.loc[gid, 'REMARKS'] = REMARKS_pdb\n",
    "                                                           \n",
    "                new_pdb = pd.concat([new_pdb, glacier_pdb], ignore_index=True)\n",
    "\n",
    "                                                           \n",
    "        elif isinstance(val[-2], list):  ## multiple polygons with PARENT_GLACIER\n",
    "\n",
    "            for sgiid in val[-2]:\n",
    "\n",
    "                # Mauro's glacier\n",
    "                mg = pdf[pdf.Code_SGI2010 == sgiid]\n",
    "                mg_ll = pdfll[pdfll.Glacier_name_SGI2010 == sgiid]\n",
    "\n",
    "                # Parent glacier ID\n",
    "                pg_id = gid\n",
    "                # new ID for the entries themselves and pop the index so that it is not used twice\n",
    "                new_id = new_ids[0]\n",
    "                new_ids.pop(0)\n",
    "\n",
    "\n",
    "                # set the REMARKS (added at the end)\n",
    "                REMARKS_pdd = ''\n",
    "                REMARKS_pda = ''\n",
    "\n",
    "                if not mg.empty:\n",
    "                    glacier_pdd.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                    glacier_pdd.loc[gid, 'NAME'] = name_to_FoG(mg.Glacier_name_SGI2010.iloc[0], name_adjust_FoG, hot_list, special_names)\n",
    "                    glacier_pdd.loc[gid, 'WGMS_ID'] = new_id\n",
    "                    glacier_pdd.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                    glacier_pdd.loc[gid, 'LOWER_BOUND'] = MISS_VAL\n",
    "                    glacier_pdd.loc[gid, 'UPPER_BOUND'] = MISS_VAL\n",
    "                    glacier_pdd.loc[gid, 'AREA_SURVEY_YEAR'] = mg.area_t2_km2.iloc[0]\n",
    "                    glacier_pdd.loc[gid, 'AREA_CHANGE'] = round((mg.area_t2_km2.iloc[0] - mg.area_t1_km2.iloc[0]) * 1000, 3)  # *1000: unit difference (1000m2 and km2)\n",
    "                    #glacier_pdd.loc[gid, 'AREA_CHANGE_UNC'] = round((area_unc(mg.area_t1_km2.iloc[0]) + area_unc(mg.area_t2_km2.iloc[0]))* 1000, -1)  # error is addition of both errors for t1 and t2 in worst case; *1000 for unit\n",
    "                    glacier_pdd.loc[gid, 'THICKNESS_CHG'] = round(((mg.dvol_mio_m3_between_t1_and_t2.iloc[0] * 10**6) / ((mg.area_t2_km2.iloc[0] + mg.area_t1_km2.iloc[0]) * 0.5 * 10**6)) * 1000) # *1000 for conversion from m thickness change to mm change\n",
    "                    #glacier_pdd.loc[gid, 'THICKNESS_CHG_UNC'] = np.nan  # berechnen? AREA_UNC fehlt und der Fehler durch Mittelung\n",
    "                    glacier_pdd.loc[gid, 'VOLUME_CHANGE'] = mg.dvol_mio_m3_between_t1_and_t2.iloc[0] *1000   # *1000: unit difference (1000m3 / 1000000m3)\n",
    "                    glacier_pdd.loc[gid, 'VOLUME_CHANGE_UNC'] = round(mg.uncertainty_dvol_between_t1_and_t2_mio_m3.iloc[0]) # *1000:unit difference (1000m3 / 1000000m3)\n",
    "                    glacier_pdd.loc[gid, 'SURVEY_DATE'] = int(mg.t2_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                    glacier_pdd.loc[gid, 'SD_PLATFORM_METHOD'] = SD_PLATFORM_METHOD # must be determined\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' Survey date method: %s.' % SD_METHOD\n",
    "                    glacier_pdd.loc[gid, 'REFERENCE_DATE'] = int(mg.t1_year.iloc[0] *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                    glacier_pdd.loc[gid, 'RD_PLATFORM_METHOD'] = RD_PLATFORM_METHOD   # must be determined\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' Reference date method: %s.' % RD_METHOD\n",
    "                    #glacier_pdd.PUB_IN_FOG = PUB_DATE      # not needed in data submission form\n",
    "                    glacier_pdd.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                    glacier_pdd.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                    glacier_pdd.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' ID SGI 1973: %s.' % mg.ID_SGI1973.iloc[0]\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' ID SGI 2010: %s.' % mg.Code_SGI2010.iloc[0]\n",
    "                    # at the very end \n",
    "                    glacier_pdd.loc[gid, 'REMARKS'] = REMARKS_pdd\n",
    "\n",
    "                    new_pdd = pd.concat([new_pdd, glacier_pdd], ignore_index=True)\n",
    "                                                               \n",
    "                                                               \n",
    "                    # Fill PDB\n",
    "                    glacier_pdb.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                    glacier_pdb.loc[gid, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0], name_adjust_FoG, hot_list, special_names)\n",
    "                    glacier_pdb.loc[gid, 'WGMS_ID'] = new_id\n",
    "                    glacier_pdb.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'HIGHEST_ELEVATION'] = mg_ll['max_elevation (masl)'].iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'MEDIAN_ELEVATION'] = mg_ll['median_elevation (masl)'].iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'LOWEST_ELEVATION'] = mg_ll['min_elevation (masl)'].iloc[0]\n",
    "                    #glacier_pdb.loc[gid, 'ELEVATION_UNC'] = np.nan\n",
    "                    glacier_pdb.loc[gid, 'LENGTH'] = round(mg_ll['length (km)'].iloc[0], -1)\n",
    "                    #glacier_pdb.loc[gid, 'LENGTH_UNC'] = mg_ll['length (km)'].iloc[0] * LENGTH_UNC_FACTOR\n",
    "                    glacier_pdb.loc[gid, 'AREA'] = mg_ll['area(km2)'].iloc[0]\n",
    "                    #glacier_pdb.loc[gid, 'AREA_UNC'] = round(area_unc(mg.area_t1_km2.iloc[0]), 2)\n",
    "                    glacier_pdb.loc[gid, 'SURVEY_DATE'] = mg_ll.year.iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'SURVEY_PLATFORM_METHOD'] = SD_PLATFORM_METHOD\n",
    "                    REMARKS_pdb = REMARKS_pdb + ' Survey date method: %s.' % SD_METHOD\n",
    "                    glacier_pdb.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                    glacier_pdb.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                    glacier_pdb.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                    glacier_pdb.loc[gid, 'REMARKS'] = REMARKS_pdb\n",
    "\n",
    "                    new_pdb = pd.concat([new_pdb, glacier_pdb], ignore_index=True)\n",
    "\n",
    "\n",
    "                if not mg_ll.empty:\n",
    "                    glacier_pda.loc[gid, 'POLTITICAL_UNIT'] = POL_UNIT\n",
    "                    glacier_pda.loc[gid, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "                    glacier_pda.loc[gid, 'WGMS_ID'] = new_id \n",
    "                    glacier_pda.loc[gid, 'LATITUDE'] = round(mg_ll['y WGS84)'].iloc[0], 6)\n",
    "                    glacier_pda.loc[gid, 'LONGITUDE'] = round(mg_ll['Location(x WGS84)'].iloc[0], 6)\n",
    "                    glacier_pda.loc[gid, 'REGION'] = RGI_REGION\n",
    "                    glacier_pda.loc[gid, 'SUBREGION'] = RGI_SUBREGION\n",
    "                    glacier_pda.loc[gid, 'PARENT_GLACIER'] = pg_id\n",
    "                    glacier_pda.loc[gid, 'SGI_2010_ID'] = sgiid\n",
    "\n",
    "                new_pda = pd.concat([new_pda, glacier_pda], ignore_index=True)\n",
    "\n",
    "    return new_pda, new_pdb, new_pdd, new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glacier de la plaine morte (no. 65) glacier ['glacier', 'de', 'la', 'plaine', 'morte', '(no.', '65)']\n",
      "65), glacier de la plaine morte\n"
     ]
    }
   ],
   "source": [
    "new_pda, new_pdb, new_pdd, new_id_range = create_entries_id_present(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, take_over_id, new_id_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_entries_new_id(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, new_id_list, new_ids):\n",
    "\n",
    "    for id_2010 in new_id_list:\n",
    "\n",
    "        # two new DFs for the different FoG files\n",
    "        glacier_pdd = pd.DataFrame(columns=new_pdd.columns.values)\n",
    "        glacier_pda = pd.DataFrame(columns=new_pda.columns.values)\n",
    "        glacier_pdb = pd.DataFrame(columns=new_pdb.columns.values)\n",
    "\n",
    "        # Mauro's entry: \n",
    "        mg = pdf[pdf.Code_SGI2010 == id_2010]\n",
    "        mg_ll = pdfll[pdfll.Glacier_name_SGI2010 == id_2010]\n",
    "        \n",
    "        # new ID for the entries themselves and pop the index so that it is not used twice\n",
    "        new_id = new_ids[0]\n",
    "        new_ids.pop(0)\n",
    "\n",
    "        # set the REMARKS (added at the end)\n",
    "        REMARKS_pdd = ''\n",
    "        REMARKS_pdb = ''\n",
    "\n",
    "        glacier_pda.loc[new_id, 'POLTITICAL_UNIT'] = POL_UNIT\n",
    "        glacier_pda.loc[new_id, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "        glacier_pda.loc[new_id, 'WGMS_ID'] = int(new_id) \n",
    "        glacier_pda.loc[new_id, 'LATITUDE'] = round(mg_ll['y WGS84)'].iloc[0], 6)\n",
    "        glacier_pda.loc[new_id, 'LONGITUDE'] = round(mg_ll['Location(x WGS84)'].iloc[0], 6)\n",
    "        glacier_pda.loc[new_id, 'REGION'] = RGI_REGION\n",
    "        glacier_pda.loc[new_id, 'SUBREGION'] = RGI_SUBREGION\n",
    "        glacier_pda.loc[new_id, 'SGI_2010_ID'] = id_2010\n",
    "\n",
    "        new_pda = pd.concat([new_pda, glacier_pda], ignore_index=True)\n",
    "\n",
    "\n",
    "        if not mg.empty:\n",
    "            glacier_pdd.loc[new_id, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "            glacier_pdd.loc[new_id, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "            glacier_pdd.loc[new_id, 'WGMS_ID'] = new_id\n",
    "            glacier_pdd.loc[new_id, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "            glacier_pdd.loc[new_id, 'LOWER_BOUND'] = MISS_VAL\n",
    "            glacier_pdd.loc[new_id, 'UPPER_BOUND'] = MISS_VAL\n",
    "            glacier_pdd.loc[new_id, 'AREA_SURVEY_YEAR'] = mg.area_t2_km2.iloc[0]\n",
    "            glacier_pdd.loc[new_id, 'AREA_CHANGE'] = round((mg.area_t2_km2.iloc[0] - mg.area_t1_km2.iloc[0]) * 1000, 2)  # *1000: unit difference (1000m2 and km2)\n",
    "            #glacier_pdd.loc[new_id, 'AREA_CHANGE_UNC'] = round((area_unc(mg.area_t1_km2.iloc[0]) + area_unc(mg.area_t2_km2.iloc[0]))* 1000, -1)  # error is addition of both errors for t1 and t2 in worst case; *1000 for unit\n",
    "            glacier_pdd.loc[new_id, 'THICKNESS_CHG'] = round(((mg.dvol_mio_m3_between_t1_and_t2.iloc[0] * 10**6) / ((mg.area_t2_km2.iloc[0] + mg.area_t1_km2.iloc[0]) * 0.5 * 10**6)) * 1000) # *1000 for conversion from m thickness change to mm change\n",
    "            #glacier_pdd.loc[new_id, 'THICKNESS_CHG_UNC'] = np.nan  # berechnen? AREA_UNC fehlt und der Fehler durch Mittelung\n",
    "            glacier_pdd.loc[new_id, 'VOLUME_CHANGE'] = round(mg.dvol_mio_m3_between_t1_and_t2.iloc[0] *1000, 1)   # *1000: unit difference (1000m3 / 1000000m3)\n",
    "            glacier_pdd.loc[new_id, 'VOLUME_CHANGE_UNC'] = round(mg.uncertainty_dvol_between_t1_and_t2_mio_m3.iloc[0]) # *1000:unit difference (1000m3 / 1000000m3)\n",
    "            glacier_pdd.loc[new_id, 'SURVEY_DATE'] = int(mg.t2_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "            glacier_pdd.loc[new_id, 'SD_PLATFORM_METHOD'] = SD_PLATFORM_METHOD # must be determined\n",
    "            REMARKS_pdd = REMARKS_pdd + ' Survey date method: %s.' % SD_METHOD\n",
    "            glacier_pdd.loc[new_id, 'REFERENCE_DATE'] = int(mg.t1_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "            glacier_pdd.loc[new_id, 'RD_PLATFORM_METHOD'] = RD_PLATFORM_METHOD   # must be determined\n",
    "            REMARKS_pdd = REMARKS_pdd + ' Reference date method: %s.' % RD_METHOD\n",
    "            #glacier_pdd.PUB_IN_FOG = PUB_DATE      # not needed in data submission form\n",
    "            glacier_pdd.loc[new_id, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "            glacier_pdd.loc[new_id, 'SPONS_AGENCY'] = AGENCY\n",
    "            glacier_pdd.loc[new_id, 'REFERENCE'] = REFERENCE\n",
    "            REMARKS_pdd = REMARKS_pdd + ' ID SGI 1973: %s.' % mg.ID_SGI1973.iloc[0]\n",
    "            REMARKS_pdd = REMARKS_pdd + ' ID SGI 2010: %s.' % mg.Code_SGI2010.iloc[0]\n",
    "            # at the very end \n",
    "            glacier_pdd.loc[new_id, 'REMARKS'] = REMARKS_pdd\n",
    "\n",
    "            new_pdd = pd.concat([new_pdd, glacier_pdd], ignore_index=True)\n",
    "                                                          \n",
    "                                                          \n",
    "            # Fill PDB\n",
    "            glacier_pdb.loc[new_id, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "            glacier_pdb.loc[new_id, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "            glacier_pdb.loc[new_id, 'WGMS_ID'] = new_id\n",
    "            glacier_pdb.loc[new_id, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'HIGHEST_ELEVATION'] = mg_ll['max_elevation (masl)'].iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'MEDIAN_ELEVATION'] = mg_ll['median_elevation (masl)'].iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'LOWEST_ELEVATION'] = mg_ll['min_elevation (masl)'].iloc[0]\n",
    "            #glacier_pdb.loc[new_id, 'ELEVATION_UNC'] = np.nan\n",
    "            glacier_pdb.loc[new_id, 'LENGTH'] = round(mg_ll['length (km)'].iloc[0], -1)\n",
    "            #glacier_pdb.loc[new_id, 'LENGTH_UNC'] = mg_ll['length (km)'].iloc[0] * LENGTH_UNC_FACTOR\n",
    "            glacier_pdb.loc[new_id, 'AREA'] = mg_ll['area(km2)'].iloc[0]\n",
    "            #glacier_pdb.loc[new_id, 'AREA_UNC'] = round(area_unc(mg.area_t1_km2.iloc[0]), 2)\n",
    "            glacier_pdb.loc[new_id, 'SURVEY_DATE'] = mg_ll.year.iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'SURVEY_PLATFORM_METHOD'] = SD_PLATFORM_METHOD\n",
    "            REMARKS_pdb = REMARKS_pdb + ' Survey date method: %s.' % SD_METHOD\n",
    "            glacier_pdb.loc[new_id, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "            glacier_pdb.loc[new_id, 'SPONS_AGENCY'] = AGENCY\n",
    "            glacier_pdb.loc[new_id, 'REFERENCE'] = REFERENCE\n",
    "            glacier_pdb.loc[new_id, 'REMARKS'] = REMARKS_pdb\n",
    "\n",
    "            new_pdb = pd.concat([new_pdb, glacier_pdb], ignore_index=True)\n",
    "                                                          \n",
    "    return new_pda, new_pdb, new_pdd, new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glacier de la plaine morte (no. 65) glacier ['glacier', 'de', 'la', 'plaine', 'morte', '(no.', '65)']\n",
      "65), glacier de la plaine morte\n",
      "glacier de la plaine morte (no. 65) glacier ['glacier', 'de', 'la', 'plaine', 'morte', '(no.', '65)']\n",
      "65), glacier de la plaine morte\n",
      "glacier de la plaine morte (no. 65) glacier ['glacier', 'de', 'la', 'plaine', 'morte', '(no.', '65)']\n",
      "65), glacier de la plaine morte\n"
     ]
    }
   ],
   "source": [
    "(new_pda, new_pdb, new_pdd, new_id_range) = create_entries_new_id(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, new_id, new_id_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the GLIMS IDs in PDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have already put the same DF into both functions taking over IDs and creating new ones, so we don't need to concat them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 glaciers are non im GLIMS\n"
     ]
    }
   ],
   "source": [
    "new_pda['GLIMS_ID'] = np.nan\n",
    "\n",
    "ct=0\n",
    "for sgi_2010_id in new_pda.SGI_2010_ID.values:\n",
    "    try:\n",
    "        new_pda.loc[new_pda[new_pda.SGI_2010_ID == sgi_2010_id].index, 'GLIMS_ID'] = glims[glims.local_id == sgi_2010_id].glac_id.iloc[0]\n",
    "    except IndexError:\n",
    "        #print('Not in GLIMS:',new_pda[new_pda.SGI_2010_ID == sgi_2010_id].NAME.iloc[0], sgi_2010_id)\n",
    "        ct += 1\n",
    "        continue\n",
    "\n",
    "# Some glaciers don't have a GLIMS entry due to their size (~0.2km2)\n",
    "print('%s glaciers are non im GLIMS' % ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are still name duplicates: Try and get the Kanton abbreviations to make them separable more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4620\n",
      "7.98894 46.1716\n",
      "5458\n",
      "7.98894 46.1716\n",
      "4701\n",
      "9.05343 46.522202\n",
      "5432\n",
      "8.22173 46.332199\n",
      "4629\n",
      "8.91128 46.855202\n",
      "4812\n",
      "8.91128 46.855202\n",
      "4596\n",
      "8.0804 46.241299\n",
      "5453\n",
      "8.0804 46.241299\n",
      "4612\n",
      "7.32228 46.087502\n",
      "5655\n",
      "7.32228 46.087502\n",
      "4586\n",
      "9.36721 46.511902\n",
      "4671\n",
      "9.36721 46.511902\n",
      "4843\n",
      "8.76307 46.7482\n",
      "4919\n",
      "8.54097 46.7677\n",
      "4599\n",
      "7.8909 46.059601\n",
      "5489\n",
      "7.8909 46.059601\n",
      "4615\n",
      "9.8732 46.401402\n",
      "5856\n",
      "9.8732 46.401402\n",
      "4598\n",
      "7.9168 46.0658\n",
      "5488\n",
      "7.9168 46.0658\n",
      "4632\n",
      "7.32254 45.966\n",
      "5687\n",
      "7.32254 45.966\n",
      "4633\n",
      "7.32382 45.970501\n",
      "5688\n",
      "7.32382 45.970501\n",
      "4617\n",
      "7.54659 46.415798\n",
      "5237\n",
      "7.54659 46.415798\n",
      "5465\n",
      "8.0015 46.1338\n",
      "5538\n",
      "7.68799 46.0513\n",
      "4594\n",
      "8.81762 46.8339\n",
      "4826\n",
      "8.81762 46.8339\n",
      "4591\n",
      "8.46511 46.771999\n",
      "4977\n",
      "8.46511 46.771999\n",
      "4585\n",
      "9.38415 46.5116\n",
      "4670\n",
      "9.38415 46.5116\n",
      "4604\n",
      "7.05444 45.9357\n",
      "5712\n",
      "7.05444 45.9357\n",
      "4631\n",
      "8.08212 46.4968\n",
      "5370\n",
      "8.08212 46.4968\n",
      "4618\n",
      "7.92056 46.0532\n",
      "5478\n",
      "7.92056 46.0532\n",
      "5190\n",
      "7.75777 46.497299\n",
      "5539\n",
      "7.70739 46.056599\n",
      "5566\n",
      "7.73003 46.181599\n",
      "4606\n",
      "8.10377 46.562302\n",
      "5127\n",
      "8.10377 46.562302\n",
      "4622\n",
      "7.98899 46.176102\n",
      "5467\n",
      "7.98899 46.176102\n",
      "4624\n",
      "7.84121 46.506901\n",
      "5170\n",
      "7.84121 46.506901\n",
      "4605\n",
      "7.05308 45.946499\n",
      "5713\n",
      "7.05308 45.946499\n",
      "4931\n",
      "8.43209 46.685001\n",
      "5361\n",
      "7.99942 46.4352\n",
      "4625\n",
      "7.84904 46.507801\n",
      "5171\n",
      "7.84904 46.507801\n",
      "4626\n",
      "8.89793 46.846401\n",
      "4807\n",
      "8.89793 46.846401\n",
      "5117\n",
      "8.07511 46.565201\n",
      "5126\n",
      "8.12078 46.5667\n",
      "5231\n",
      "7.59332 46.3843\n",
      "5248\n",
      "7.19716 46.3157\n",
      "5333\n",
      "7.9484 46.405701\n",
      "5334\n",
      "7.93554 46.421101\n",
      "5351\n",
      "7.96617 46.494701\n",
      "5352\n",
      "8.00801 46.5098\n",
      "5602\n",
      "7.56 46.012798\n",
      "4607\n",
      "8.025621 46.5718\n",
      "5132\n",
      "8.025621 46.5718\n",
      "4600\n",
      "7.87155 46.064201\n",
      "5490\n",
      "7.87155 46.064201\n",
      "4608\n",
      "7.51662 46.379799\n",
      "5238\n",
      "7.51662 46.379799\n",
      "4628\n",
      "8.8871 46.834\n",
      "4811\n",
      "8.8871 46.834\n",
      "4619\n",
      "7.90374 46.050598\n",
      "5479\n",
      "7.90374 46.050598\n",
      "4838\n",
      "8.82182 46.7934\n",
      "4851\n",
      "8.68558 46.7365\n",
      "4896\n",
      "8.48363 46.714199\n",
      "4634\n",
      "7.32511 45.974098\n",
      "5689\n",
      "7.32511 45.974098\n",
      "4593\n",
      "8.92085 46.6311\n",
      "4713\n",
      "8.92085 46.6311\n",
      "4587\n",
      "7.6754 46.426399\n",
      "5223\n",
      "7.6754 46.426399\n",
      "4623\n",
      "7.83847 46.487999\n",
      "5149\n",
      "7.83847 46.487999\n",
      "4602\n",
      "7.86785 46.0867\n",
      "5492\n",
      "7.86785 46.0867\n",
      "4610\n",
      "7.54523 46.3843\n",
      "5257\n",
      "7.54523 46.3843\n",
      "4609\n",
      "7.48023 46.382599\n",
      "5256\n",
      "7.48023 46.382599\n",
      "5084\n",
      "8.18946 46.628399\n",
      "5384\n",
      "8.16933 46.491798\n",
      "4636\n",
      "10.352 46.765499\n",
      "5835\n",
      "10.352 46.765499\n",
      "5353\n",
      "8.07696 46.5004\n",
      "5369\n",
      "8.07304 46.4995\n",
      "4635\n",
      "7.31739 45.962398\n",
      "5692\n",
      "7.31739 45.962398\n",
      "4590\n",
      "8.44935 46.769402\n",
      "4968\n",
      "8.44935 46.769402\n",
      "4592\n",
      "8.93378 46.6264\n",
      "4712\n",
      "8.93378 46.6264\n",
      "4616\n",
      "7.52706 46.404999\n",
      "5241\n",
      "7.52706 46.404999\n",
      "4815\n",
      "8.87164 46.844101\n",
      "4817\n",
      "8.86792 46.8522\n",
      "4611\n",
      "7.32876 46.080299\n",
      "5654\n",
      "7.32876 46.080299\n",
      "4603\n",
      "7.87832 46.102798\n",
      "5493\n",
      "7.87832 46.102798\n",
      "4831\n",
      "8.75285 46.812199\n",
      "4961\n",
      "8.48833 46.821201\n",
      "4614\n",
      "9.89709 46.411701\n",
      "5855\n",
      "9.89709 46.411701\n",
      "4597\n",
      "8.07647 46.237701\n",
      "5784\n",
      "8.07647 46.237701\n",
      "4595\n",
      "8.83885 46.843601\n",
      "4825\n",
      "8.83885 46.843601\n",
      "4674\n",
      "9.35953 46.515701\n",
      "5903\n",
      "9.94344 46.739201\n",
      "4588\n",
      "7.67412 46.430901\n",
      "5222\n",
      "7.67412 46.430901\n",
      "4601\n",
      "7.87294 46.075901\n",
      "5491\n",
      "7.87294 46.075901\n",
      "4613\n",
      "7.3223 46.079399\n",
      "5658\n",
      "7.3223 46.079399\n",
      "4627\n",
      "8.91915 46.855099\n",
      "4808\n",
      "8.91915 46.855099\n",
      "4621\n",
      "7.99537 46.167099\n",
      "5459\n",
      "7.99537 46.167099\n",
      "4589\n",
      "7.68191 46.4273\n",
      "5229\n",
      "7.68191 46.4273\n",
      "4630\n",
      "8.08986 46.490398\n",
      "5354\n",
      "8.08986 46.490398\n",
      "5595\n",
      "7.57823 46.073002\n",
      "5647\n",
      "7.35982 46.058701\n"
     ]
    }
   ],
   "source": [
    "namedupl = [item for item, count in collections.Counter(new_pda.NAME.values).items() if count > 1]\n",
    "fc = fiona.open(ch_adm_path)\n",
    "\n",
    "for name in namedupl:\n",
    "    id_list = new_pda[new_pda.NAME == name].WGMS_ID.values\n",
    "    \n",
    "    for wgms_id in id_list:\n",
    "        print(wgms_id)\n",
    "        lon = new_pda[new_pda.WGMS_ID == wgms_id].LONGITUDE.iloc[0]\n",
    "        lat = new_pda[new_pda.WGMS_ID == wgms_id].LATITUDE.iloc[0]\n",
    "        print(lon, lat)\n",
    "        point = Point(lon,lat)\n",
    "        \n",
    "        for feature in fc:\n",
    "            if shape(feature['geometry']).contains(point):\n",
    "                new_pda.loc[new_pda[new_pda.WGMS_ID == wgms_id].index,'NAME'] = name + ' ' + feature['properties']['HASC_1'].split('.')[1]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the columns in order to be able to insert this easily into the data submission form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pda = new_pda[['POLTITICAL_UNIT', 'NAME', 'WGMS_ID', 'RIVER_BASIN', 'FREE_POSITION', 'LOCAL_CODE', 'LOCAL_PSFG', 'GEN_LOCATION', 'SPEC_LOCATION', 'LATITUDE', 'LONGITUDE', 'PRIM_CLASSIFIC', 'FORM', 'FRONTAL_CHARS', 'EXPOS_ACC_AREA', 'EXPOS_ABL_AREA', 'PARENT_GLACIER', 'REMARKS', 'REGION', 'SUBREGION', 'GLIMS_ID']]\n",
    "new_pdb = new_pdb[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'HIGHEST_ELEVATION', 'MEDIAN_ELEVATION', 'LOWEST_ELEVATION', 'ELEVATION_UNC', 'LENGTH', 'LENGTH_UNC', 'AREA', 'AREA_UNC', 'SURVEY_DATE', 'SURVEY_PLATFORM_METHOD', 'INVESTIGATOR', 'SPONS_AGENCY', 'REFERENCE', 'REMARKS']]\n",
    "new_pdd = new_pdd[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'LOWER_BOUND', 'UPPER_BOUND', 'AREA_SURVEY_YEAR', 'AREA_CHANGE', 'AREA_CHANGE_UNC', 'THICKNESS_CHG', 'THICKNESS_CHG_UNC', 'VOLUME_CHANGE', 'VOLUME_CHANGE_UNC', 'SURVEY_DATE', 'SD_PLATFORM_METHOD', 'REFERENCE_DATE', 'RD_PLATFORM_METHOD', 'INVESTIGATOR', 'SPONS_AGENCY', 'REFERENCE', 'REMARKS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Excel format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_pda.to_excel('c:\\\\users\\\\jlandman\\\\Desktop\\\\PDA_submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pdb.to_excel('c:\\\\users\\\\jlandman\\\\Desktop\\\\PDB_submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_pdd.to_excel('c:\\\\users\\\\jlandman\\\\Desktop\\\\PDD_submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1336-eeea6528e876>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1336-eeea6528e876>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for key,value in links.items()\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for key,value in links.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to RGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check is point is within an RGI polygon and if the area matches by +/-10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgi = fiona.open(rgi_CE)\n",
    "rgi_links = new_pda.copy()\n",
    "rgi_links['RGI_ID'] = np.nan\n",
    "\n",
    "for fog_id in rgi_links.WGMS_ID.values:\n",
    "    ix = rgi_links.index[rgi_links.WGMS_ID == fog_id]\n",
    "    print(fog_id)\n",
    "    lon = rgi_links[rgi_links.WGMS_ID == fog_id].LONGITUDE.iloc[0]\n",
    "    lat = rgi_links[rgi_links.WGMS_ID == fog_id].LATITUDE.iloc[0]\n",
    "    print(lon, lat)\n",
    "    point = Point(lon,lat)\n",
    "\n",
    "    for feature in rgi:\n",
    "        if shape(feature['geometry']).contains(point):\n",
    "            print(feature['properties']['RGIId'], ix)\n",
    "            rgi_links.loc[ix, 'RGI_ID'] = feature['properties']['RGIId']\n",
    "            \n",
    "rgi_links.to_csv('sgi2010_rgi_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rgi_links.dropna(subset=['RGI_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "su =0\n",
    "app=0\n",
    "for key,value in links.items():\n",
    "    if isinstance(value[-2], list):\n",
    "        su+= len(value[-2])\n",
    "        app+=1\n",
    "        \n",
    "    #else:\n",
    "    #    su+=1\n",
    "print(su)\n",
    "print(app)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rgi = fiona.open(rgi_CE)\n",
    "rgi_links = new_pda.copy()\n",
    "rgi_links['RGI_ID'] = np.nan\n",
    "\n",
    "for fog_id in rgi_links.WGMS_ID.values:\n",
    "    close = pd.DataFrame([])\n",
    "    ix = rgi_links.index[rgi_links.WGMS_ID == fog_id]\n",
    "    lon = rgi_links[rgi_links.WGMS_ID == fog_id].LONGITUDE.iloc[0]\n",
    "    lat = rgi_links[rgi_links.WGMS_ID == fog_id].LATITUDE.iloc[0]\n",
    "    print(fog_id, lon, lat)\n",
    "    point = Point(lon,lat)\n",
    "\n",
    "    for feature in rgi:\n",
    "        close.loc[feature['properties']['RGIId'], 'Distance'] = haversine(lon, lat, feature['properties']['CenLon'], feature['properties']['CenLat'])\n",
    "        #close.loc[feature['properties']['RGIId'], 'Geometry'] = shape(feature['geometry'])\n",
    "    close = close.sort(columns='Distance')\n",
    "    close = close.reset_index()\n",
    "    \n",
    "    ct=0\n",
    "    while ct<10: \n",
    "        feature = filter(rgi['properties'].get(['RGIId'] == close[ct].RGI_ID), rgi)\n",
    "        print(feature)\n",
    "        if shape(feature['geometry']).contains(point):\n",
    "            print(feature['properties']['RGIId'], ix)\n",
    "            rgi_links.loc[ix, 'RGI_ID'] = feature['properties']['RGIId']\n",
    "            \n",
    "        ct+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
