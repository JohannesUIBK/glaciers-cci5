{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "from difflib import SequenceMatcher\n",
    "import salem\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import os\n",
    "import shapely.geometry as shpg\n",
    "import shapely.ops\n",
    "import collections\n",
    "from shapely.geometry import Point, shape\n",
    "import fiona\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\database_Fischer_et_al._2015_The_Cryosphere.txt'                 # Fischer database with swiss coordinates \n",
    "fll_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\SGI2010wgs84_shapefiles\\\\parameters_SGI2010.csv'               # Fischer database with lat/lon\n",
    "a_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\DOI-WGMS-FoG-2015-11\\\\WGMS-FoG-2015-11-A-GENERAL-INFORMATION.csv'# FoG: A GENERAL\n",
    "b_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\DOI-WGMS-FoG-2015-11\\\\WGMS-FoG-2015-11-B-STATE.csv'              # FoG: B STATE\n",
    "d_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\DOI-WGMS-FoG-2015-11\\\\WGMS-FoG-2015-11-D-CHANGE.csv'             # FoG: D CHANGE\n",
    "gl_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\glims_db_20160429\\\\glims_polygons_swiss_alps.txt'               # GLIMS DBF file\n",
    "ch_adm_path = \"C:\\\\Users\\\\jlandman\\\\Desktop\\\\CHE_adm_shp\\\\CHE_adm1.shp\"                                  # Swiss Kanton borders\n",
    "rgi_CE = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\rgi50\\\\11_rgi50_CentralEurope\\\\11_rgi50_CentralEurope.shp'       # RGI 5.0 Central Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(f_path, sep = '\\t', encoding='iso-8859-1')\n",
    "pdfll = pd.read_csv(fll_path, sep= ';', encoding='iso-8859-1')  #, usecols=[2,3,6,14,15]\n",
    "pda = pd.read_csv(a_path, encoding='iso-8859-1')\n",
    "pdb = pd.read_csv(b_path, encoding='iso-8859-1')\n",
    "pdd = pd.read_csv(d_path, encoding='iso-8859-1')\n",
    "glims = pd.read_csv(gl_path, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preselect FoG IDs in Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda = pda[pda.POLITICAL_UNIT == 'CH']\n",
    "pdb = pdb[pdb.WGMS_ID.isin(pda.WGMS_ID.values)]\n",
    "pdd = pdd[pdd.WGMS_ID.isin(pdd.WGMS_ID.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haversine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct missing underscores and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = pdf.rename(columns={'uncertainty_dvol_between_t1_and_t2_mio m3': 'uncertainty_dvol_between_t1_and_t2_mio_m3'})\n",
    "pdfll = pdfll.rename(columns={'uncertainty_dvol_between_t1_and_t2_mio m3': 'uncertainty_dvol_between_t1_and_t2_mio_m3'})\n",
    "\n",
    "pdfll = pdfll.rename(columns={'Unnamed: 15': 'Glacier_name_SGI2010'})\n",
    "pdfll = pdfll.rename(columns={'Unnamed: 16': 'year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach: find matching glaciers based on FoG => compare names, area and location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of strings and symbols that should be replaced prior to calculation of similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_adjust = {'gletscher':'g', 'glacier':'g' , 'vadret':'v', 'ghiacciaio':'g', 'vedretta':'v', 'ferner':'f', 'ä':'ae', 'ö':'oe', 'ü':'ue', 'é':'e', 'à':'a', 'è':'e', 'ô':'o', 'ß':'ss'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce FoG column with new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pda['FoG_compname'] = ''\n",
    "\n",
    "for initname in [n for n in pda.NAME.values]:\n",
    "    name = initname.lower()\n",
    "    for key in name_adjust:\n",
    "        if key in name:\n",
    "            name = name.replace(key, name_adjust[key])\n",
    "    #pda.FoG_compname[pda.NAME == initname] = name\n",
    "    pda.loc[pda.NAME == initname, 'FoG_compname'] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce some new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf.COMPNAME = ''              # simplified name \n",
    "pda.MATCH_RATIO = np.nan       # string matching ratio \n",
    "pda.MATCH_NAME = ''            # Name of the FoG glacier that matches Mauro's name best\n",
    "pda.CLOSEST = ''               # closest FoG glacier point\n",
    "pda.DIST_TO_CLOSEST = np.nan   # distance of Mauro's point to the closest FoG point \n",
    "pda.AREA_CLOSEST = np.nan      # column with the area of Mauro's glacier found by string matching \n",
    "pda.AREA_MATCH = np.nan        # column with the area of Mauro's glacier found by string matching\n",
    "pda.AREA = np.nan              # Area that will be grabbed from the PDB file, if present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust also Mauro's names to make them comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx,cols in pdf.iterrows():\n",
    "    # simplify name\n",
    "    compname_mau = cols.Glacier_name_SGI2010.lower()\n",
    "    for key in name_adjust:\n",
    "        if key in compname_mau:\n",
    "            # replace the umlauts etc.\n",
    "            compname_mau = compname_mau.replace(key, name_adjust[key])\n",
    "    \n",
    "    # delete the bracket stuff in order to improve the ratio\n",
    "    start = compname_mau.find('(')\n",
    "    if start != -1:\n",
    "        compname_mau = compname_mau[0:start]\n",
    "    compname_mau = compname_mau.replace('*', '')\n",
    "    compname_mau = compname_mau.strip()\n",
    "\n",
    "    pdf.loc[pdf.Glacier_name_SGI2010 == cols.Glacier_name_SGI2010, 'COMPNAME'] = compname_mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdfll.COMPNAME = ''              # simplified name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx,cols in pdfll.iterrows():\n",
    "    # simplify name\n",
    "    compname_mau = cols.Names.lower()\n",
    "    for key in name_adjust:\n",
    "        if key in compname_mau:\n",
    "            # replace the umlauts etc.\n",
    "            compname_mau = compname_mau.replace(key, name_adjust[key])\n",
    "    \n",
    "    # delete the bracket stuff in order to improve the ratio\n",
    "    start = compname_mau.find('(')\n",
    "    if start != -1:\n",
    "        compname_mau = compname_mau[0:start]\n",
    "    compname_mau = compname_mau.replace('*', '')\n",
    "    compname_mau = compname_mau.strip()\n",
    "\n",
    "    pdfll.loc[pdfll.Names == cols.Names, 'COMPNAME'] = compname_mau\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matching glaciers for the 159 swiss glaciers in PDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if os.path.exists('assigned_automated.csv'):\n",
    "#    pass\n",
    "\n",
    "#else:\n",
    "for fidx,fcols in pda.iterrows():\n",
    "\n",
    "    # create an AREA column entry (from the PDB (\"state\") table)\n",
    "    area_match = np.nan\n",
    "    try: # take the latest area entry\n",
    "        area_match = pdb[pdb.WGMS_ID == fcols.WGMS_ID].AREA.values[~np.isnan(pdb[pdb.WGMS_ID == fcols.WGMS_ID].AREA.values)][-1]\n",
    "    except IndexError:\n",
    "        area_match = np.nan\n",
    "    pda.loc[pda.WGMS_ID == fcols.WGMS_ID, 'AREA'] = area_match\n",
    "\n",
    "\n",
    "    # find biggest ratio of string matching and insert\n",
    "    ratio = 0.0\n",
    "    name = ''\n",
    "    for cname in pdfll['COMPNAME'].values:\n",
    "        curr_ratio = SequenceMatcher(None, cname, fcols.FoG_compname).ratio()\n",
    "\n",
    "        if curr_ratio > ratio or ratio==0.0:  #the latter in order to catch the initial case\n",
    "            ratio = curr_ratio\n",
    "            name = cname\n",
    "\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'MATCH_RATIO'] = ratio\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'MATCH_NAME'] = name\n",
    "\n",
    "    # insert the area (at t2, because this is the latest) of the glacier found by string matching\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'AREA_MATCH'] = pdfll[pdfll['COMPNAME'] == name]['area(km2)'].iloc[0]\n",
    "\n",
    "\n",
    "    #find closest pdf glacier\n",
    "    dist = np.nan\n",
    "    close_name = ''\n",
    "    for pdf_idx, pdf_cols in pdfll.iterrows():\n",
    "        lat = pdfll[pdfll.Names == pdf_cols.Names]['y WGS84)'].values[0]\n",
    "        lon = pdfll[pdfll.Names == pdf_cols.Names]['Location(x WGS84)'].values[0]\n",
    "        curr_dist = haversine(lon, lat, fcols.LONGITUDE, fcols.LATITUDE)\n",
    "\n",
    "        if curr_dist < dist or pd.isnull(dist): # the second is for the initial loop\n",
    "            dist = curr_dist\n",
    "            close_name = pdf_cols.COMPNAME\n",
    "\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'DIST_TO_CLOSEST'] = dist\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'CLOSEST'] = close_name\n",
    "\n",
    "    print(fcols.NAME)\n",
    "    # insert the area (at t2, because this is the latest) of the glacier ehic is found to be the closest\n",
    "    pda.loc[pda.NAME == fcols.NAME, 'AREA_CLOSEST'] = pdfll[pdfll['COMPNAME'] == close_name]['area(km2)'].iloc[0]\n",
    "\n",
    "\n",
    "    pda.to_csv('assigned_automated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pda.to_csv('assigned_automated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Okay the automated assignment is not always good (high polygon density, too many similar names...) => Check everything manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 'BREITHORN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID = pda[pda.NAME == i].WGMS_ID.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLITICAL_UNIT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WGMS_ID</th>\n",
       "      <th>RIVER_BASIN</th>\n",
       "      <th>FREE_POSITION</th>\n",
       "      <th>LOCAL_CODE</th>\n",
       "      <th>LOCAL_PSFG</th>\n",
       "      <th>GEN_LOCATION</th>\n",
       "      <th>SPEC_LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>...</th>\n",
       "      <th>GEO-REGION_CODE</th>\n",
       "      <th>GEO-SUBREGION_CODE</th>\n",
       "      <th>FoG_compname</th>\n",
       "      <th>AREA</th>\n",
       "      <th>MATCH_RATIO</th>\n",
       "      <th>MATCH_NAME</th>\n",
       "      <th>AREA_MATCH</th>\n",
       "      <th>DIST_TO_CLOSEST</th>\n",
       "      <th>CLOSEST</th>\n",
       "      <th>AREA_CLOSEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>CH</td>\n",
       "      <td>BREITHORN</td>\n",
       "      <td>2311</td>\n",
       "      <td>4R014</td>\n",
       "      <td>4M</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.48</td>\n",
       "      <td>...</td>\n",
       "      <td>CEU</td>\n",
       "      <td>CEU-01</td>\n",
       "      <td>breithorn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>breithorng</td>\n",
       "      <td>2.71188</td>\n",
       "      <td>143.257626</td>\n",
       "      <td>tschingelhorn-ne</td>\n",
       "      <td>0.01787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    POLITICAL_UNIT       NAME  WGMS_ID RIVER_BASIN FREE_POSITION LOCAL_CODE  \\\n",
       "711             CH  BREITHORN     2311       4R014            4M         19   \n",
       "\n",
       "    LOCAL_PSFG GEN_LOCATION SPEC_LOCATION  LATITUDE     ...       \\\n",
       "711        NaN          NaN           NaN     46.48     ...        \n",
       "\n",
       "     GEO-REGION_CODE  GEO-SUBREGION_CODE FoG_compname  AREA MATCH_RATIO  \\\n",
       "711              CEU              CEU-01    breithorn   NaN    0.947368   \n",
       "\n",
       "     MATCH_NAME  AREA_MATCH DIST_TO_CLOSEST           CLOSEST AREA_CLOSEST  \n",
       "711  breithorng     2.71188      143.257626  tschingelhorn-ne      0.01787  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pda[pda.NAME == i]#[['LATITUDE', 'LONGITUDE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLITICAL_UNIT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WGMS_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>HIGHEST_ELEVATION</th>\n",
       "      <th>MEDIAN_ELEVATION</th>\n",
       "      <th>LOWEST_ELEVATION</th>\n",
       "      <th>ELEVATION_UNC</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>LENGTH_UNC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA_UNC</th>\n",
       "      <th>SURVEY_DATE</th>\n",
       "      <th>SURVEY_PLATFORM_METHOD</th>\n",
       "      <th>PUB_IN_FOG</th>\n",
       "      <th>INVESTIGATOR</th>\n",
       "      <th>SPONS_AGENCY</th>\n",
       "      <th>REFERENCE</th>\n",
       "      <th>REMARKS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [POLITICAL_UNIT, NAME, WGMS_ID, YEAR, HIGHEST_ELEVATION, MEDIAN_ELEVATION, LOWEST_ELEVATION, ELEVATION_UNC, LENGTH, LENGTH_UNC, AREA, AREA_UNC, SURVEY_DATE, SURVEY_PLATFORM_METHOD, PUB_IN_FOG, INVESTIGATOR, SPONS_AGENCY, REFERENCE, REMARKS]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb[pdb.where(~pd.isnull(pdb.AREA)).WGMS_ID == ID].tail(10)#[['NAME', 'LENGTH', 'AREA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>acquisition date</th>\n",
       "      <th>Location(x WGS84)</th>\n",
       "      <th>y WGS84)</th>\n",
       "      <th>Location(x CH1903</th>\n",
       "      <th>y CH1903)</th>\n",
       "      <th>area(km2)</th>\n",
       "      <th>min_elevation (masl)</th>\n",
       "      <th>max_elevation (masl)</th>\n",
       "      <th>median_elevation (masl)</th>\n",
       "      <th>average_elevation (masl)</th>\n",
       "      <th>length (km)</th>\n",
       "      <th>average_slope (degree)</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Names</th>\n",
       "      <th>Glacier_name_SGI2010</th>\n",
       "      <th>year</th>\n",
       "      <th>COMPNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>B73_13</td>\n",
       "      <td>2010</td>\n",
       "      <td>7.50573</td>\n",
       "      <td>45.976799</td>\n",
       "      <td>605183.4</td>\n",
       "      <td>91865.6</td>\n",
       "      <td>0.16359</td>\n",
       "      <td>3420</td>\n",
       "      <td>3615</td>\n",
       "      <td>3572</td>\n",
       "      <td>3561.0</td>\n",
       "      <td>0.373</td>\n",
       "      <td>25.8</td>\n",
       "      <td>NW</td>\n",
       "      <td>Mont Collon N-I*</td>\n",
       "      <td>B73/13</td>\n",
       "      <td>2010</td>\n",
       "      <td>mont collon n-i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>B73_14</td>\n",
       "      <td>2010</td>\n",
       "      <td>7.49025</td>\n",
       "      <td>45.975102</td>\n",
       "      <td>603802.9</td>\n",
       "      <td>91572.5</td>\n",
       "      <td>5.43500</td>\n",
       "      <td>2168</td>\n",
       "      <td>3649</td>\n",
       "      <td>3086</td>\n",
       "      <td>3066.0</td>\n",
       "      <td>5.106</td>\n",
       "      <td>16.2</td>\n",
       "      <td>NW</td>\n",
       "      <td>MONT COLLON GLACIER DU (Teilgl. von B73/32n)</td>\n",
       "      <td>B73/14</td>\n",
       "      <td>2010</td>\n",
       "      <td>mont collon g du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>B73_31n</td>\n",
       "      <td>2010</td>\n",
       "      <td>7.50832</td>\n",
       "      <td>45.982201</td>\n",
       "      <td>605385.7</td>\n",
       "      <td>92357.7</td>\n",
       "      <td>0.02378</td>\n",
       "      <td>3067</td>\n",
       "      <td>3252</td>\n",
       "      <td>3169</td>\n",
       "      <td>3166.0</td>\n",
       "      <td>0.183</td>\n",
       "      <td>42.7</td>\n",
       "      <td>N</td>\n",
       "      <td>Mont Collon-N-II*</td>\n",
       "      <td>B73/31n</td>\n",
       "      <td>2010</td>\n",
       "      <td>mont collon-n-ii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  acquisition date  Location(x WGS84)   y WGS84)  \\\n",
       "1081   B73_13              2010            7.50573  45.976799   \n",
       "1082   B73_14              2010            7.49025  45.975102   \n",
       "1092  B73_31n              2010            7.50832  45.982201   \n",
       "\n",
       "      Location(x CH1903  y CH1903)  area(km2)  min_elevation (masl)  \\\n",
       "1081           605183.4    91865.6    0.16359                  3420   \n",
       "1082           603802.9    91572.5    5.43500                  2168   \n",
       "1092           605385.7    92357.7    0.02378                  3067   \n",
       "\n",
       "      max_elevation (masl)  median_elevation (masl)  average_elevation (masl)  \\\n",
       "1081                  3615                     3572                    3561.0   \n",
       "1082                  3649                     3086                    3066.0   \n",
       "1092                  3252                     3169                    3166.0   \n",
       "\n",
       "      length (km)  average_slope (degree) aspect  \\\n",
       "1081        0.373                    25.8     NW   \n",
       "1082        5.106                    16.2     NW   \n",
       "1092        0.183                    42.7      N   \n",
       "\n",
       "                                             Names Glacier_name_SGI2010  year  \\\n",
       "1081                              Mont Collon N-I*               B73/13  2010   \n",
       "1082  MONT COLLON GLACIER DU (Teilgl. von B73/32n)               B73/14  2010   \n",
       "1092                             Mont Collon-N-II*              B73/31n  2010   \n",
       "\n",
       "              COMPNAME  \n",
       "1081   mont collon n-i  \n",
       "1082  mont collon g du  \n",
       "1092  mont collon-n-ii  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfll[pdfll['Names'].str.contains('mont collon', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A dictionary with links from FoG to Mauro's database (names in FoG to full names, short names and IDs in Mauro's DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = {\n",
    "    'A NEUVE GL. L\\'':(['A NEUVE GLACIER DE L\\'-S','A NEUVE GLACIER DE L\\'-N'],['a neuve g de l\\'-s','a neuve g de l\\'-n'],['B85/07','B85/08'],True), # no area in FoG\n",
    "    'ADLER':('ADLERGLETSCHER (Teilgl. von B56/03)','adlerg','B56/14n', True),  # no area in FoG, but quite obvious\n",
    "    'ALBIGNA':('ALBIGNA VADREC D\\' (Nr. 116)','albigna vadrec d\\'', 'C84/16', True),  # ok, error in area in pdb  \n",
    "    'ALLALIN':('Allalingletscher* (Teilgl. von B52/66n)','allaling', 'B52/29', True), #ok area 9.68/9.17\n",
    "    'ALPETLI(KANDER)':('KANDERFIRN (Teilgl. von A55B/29n; Nr. 109)','kanderfirn','A55B/13',True),  # ok area 14/12\n",
    "    'ALTELS':(['Altels-S','Altels-NW','Altels-SE'],['altels-s','altels-nw','altels-se'],['A55C/04','A55C/03','A55C/18n'],True),     # no area in FoG \n",
    "    'AMMERTEN':(['Ammerten-W','AMMERTEN-E (Nr.111)'],['ammerteng-w','ammerteng-e'],['A55F/07n','A55F/01'],True),   # ok area 1.89/(0.55+0.22)\n",
    "    'AROLLA (BAS)':('MONT COLLON GLACIER DU (Teilgl. von B73/32n)','mont collon g du','B73/14',True),  # no equivalent in Mauro's DB (is included in Glacier du Mont Collon B73/14)\n",
    "    'BALMHORN':('BALMHORNGLETSCHER (Teilgl. von A55B/42n)','balmhorng','A55B/18',True),  # ok (area: 1.7/1.9)\n",
    "    'BASODINO':('BASODINO GH. DEL (Nr. 104)','basodino gh. del','C14/10',True),  # area bigger in Mauro's DB, even for only BASODINO GH. DEL (Nr. 104) (1.84/1.89). What to do with basodino-N and basodino-NW?\n",
    "    'BELLA TOLA':('BELLA TOLA GLETSCHER (Nr. 21)','bella tola g','B61/02',True),  # ok even though areas 0.31/0.07\n",
    "    'BIDER':('BIDERGLETSCHER','biderg','B53/08',True),  # ok (no area in FoG, but unique)\n",
    "    'BIFERTEN':('BIFERTENFIRN (Nr. 77)','bifertenfirn','A50I/12',True),  # ok (area: 2.86/2.5)\n",
    "    'BIRCH':('BIRCHGLETSCHER','birchg','B32/06',True),   # ok even though area 0.54/0.22\n",
    "    'BIS':('BISGLETSCHER (Nr. 107)','bisg','B58/08',True),    # ok even though area 4.79/3.82\n",
    "    'BLUEMLISALP':('BLÜMLISALPGLETSCHER (Nr. 64)','bluemlisalpg','A55B/02',True), # ok due to lat/lon area 2.22/2.98\n",
    "    'BODMER':('BODMER','bodmerg','C02/02',True),   # Link should be okay but area 0.64/0.32\n",
    "    'BOVEYRE':('BOVEIRE GLACIER DE (Nr. 41)','boveire g de','B84/04',True),  # ok (area 1.99/1.62)\n",
    "    'BREITHORN':('BREITHORNGLETSCHER','breithorng','A54M/19',True),   # Wetterlückengletscher (not in FoG) is added and oberer breithorngletscher becomes separate, no area/length in FoG for BREITHORN\n",
    "    'BRENEY':('BRENAY GLACIER DU (Nr. 36)','brenay g du','B82/19',True),   # ok areas 9.8/7.1\n",
    "    'BRESCIANA':('BRESCIANA VADRECC DI (Nr. 103)','bresciana vadrecc di','C44/02',True),  # ok even though area 0.94/0.48\n",
    "    'BRUNEGG':('BRUNEGGGLETSCHER (Teilgl. von B60/09; Nr. 20)','bruneggg','B60/20n',True),  # ok areas 6.1/5.5\n",
    "    'BRUNNI':('BRUNNIFIRN (Nr. 72)','brunnifirn','A51D/15',True),  # ok areas 2.99/2.31\n",
    "    'CALDERAS':('CALDERAS VADRET (Nr. 95)','calderas v','E35/17',True),   # ok even though areas 1.2/0.66\n",
    "    'CAMBRENA':('Cambrena Vadret dal (Teilgl. von C93/09)','cambrena v dal','C93/11n',True),  # ok area 1.77/1.26; Cambrena-E* (Teilgl. von C93/09) C93/08 excluded due to FoG lat/lon lying upstream \n",
    "    'CAVAGNOLI':('CAVAGNÖÖ GH. DEL (Nr. 119)','cavagnoeoe gh. del','C14/17',True), # ok due to lat/lon area 1.32/0.44 (ok as compared with SGI1973)\n",
    "    'CHEILLON':('CHEILON GLACIER DE (Nr. 29)','cheilon g de','B74/08',True), # okay even though area 4.73/3.6. Spelling?\n",
    "    'CLARIDENFIRN':(['CLARIDEN FIRN-II','CLARIDEN FIRN-IV*','CLARIDEN FIRN-I','CLARIDEN FIRN-I (Spitzalpelifirn)*','CLARIDEN FIRN-III*'],['clariden firn-ii','clariden firn-iv','clariden firn-i','clariden firn-iii'],['A50I/19','A50I/20','A50I/23n','A50I/24n'],True),  # area in FoG-D:5.12, but consistent over time even though volume changes!?\n",
    "    'CORBASSIERE':('Corbassière (Teilgl. von B83/03)*','corbassiere','B83/15n',True),  # ok. unclear if also Combin de Corbassière-E (Teilgl. von B83/03)* is meant (area: 0.4km2), but separated by ridge\n",
    "    'CORNO':('CORNO GH. DEL (Nr. 120)','corno gh. del','C34/01',True),  # ok even though area 0.27/0.1\n",
    "    'CROSLINA':('CROSLINA GRANDE GH. DI (Nr. 121)','croslina grande gh. di','C32/02',True), # ok even though area 0.47/0.11 (lat/lon!)\n",
    "    'DAMMA':('DAMMAGLETSCHER (Nr. 70)','dammag','A51F/10',True),  # ok even though area 6.32/4.24\n",
    "    'DOLENT GL. DU':('DOLENT GLACIER DU','dolent g du','B85/04',True),  # ok even though noe area given in FoG\n",
    "    'DUNGEL':('TUNGELGLETSCHER (Teilgl. von A56D/09n, Nr. 112)','tungelg','A56D/01',True),  #ok area 1.2/0.93\n",
    "    'EIGER':('EIGERGLETSCHER (Nr. 59)','eigerg','A54M/03',True),   # ok area 2.27/1.53\n",
    "    'EIGER (WEST)':('Eiger Südwestgrat*','eiger suedwestgrat','A54M/02',True),  # unclear, possibly  A54M/02\n",
    "    'EN DARREY':('EN DARREY GLACIER DE L\\' (Nr. 30)','en darrey g de l\\'','B74/11',True), #ok (areas 1.86/1.28)\n",
    "    'FEE NORTH':(['FEEGLETSCHER-S-I','FEEGLETSCHER-S-II','Feegletscher-N-I (Alphubel)* (Teilgl. von B53/16n)','Feegletscher-N-I (Täschhorn)* (Teilgl. von B53/16n)','Feegletscher-N-I (Dom)* (Teilgl. von B53/16n)','FEEGLETSCHER-N-II',],['feeg-s-i','feeg-s-ii','feeg-n-i','feeg-n-i','feeg-n-i','feeg-n-ii'],['B53/14n','B53/15n','B53/17n','B53/18n','B53/19n','B53/20n'],True),  # Feechopf-W* B55/17 ???\n",
    "    'FERPECLE':('FERPÈCLE GLACIER DE (Nr. 25)','ferpecle g de','B72/11',True),  # ok areas 9.79/9.0\n",
    "    'FIESCHER':('FIESCHERGLETSCHER VS (Teilgl. von B40/14n, Nr. 4)','fiescherg vs','B40/07',True), # ok area 33.06/29.48\n",
    "    'FINDELEN':('Findelengletscher * (Teilgl. von B56/03)','findeleng','B56/16n',True),  # ok even though area 19/14\n",
    "    'FIRNALPELI':(['FIRNALPELIGLETSCHER-E (Nr. 75)','FIRNALPELIFIRN'],['firnalpelig-e','firnalpelifirn'],['A51H/13','A51H/23n'],True),  # FoG lat/lon unclear; must be this combination due to elevation extent\n",
    "    'FORNO':('FORNO VADREC DEL (Nr. 102)','forno vadrec del','C83/12',True), # ok area 8.7/5.3; NICHT Ofenhorn-W* (lat/lon!)\n",
    "    'GAMCHI':('GAMCHIGLETSCHER (Nr. 61)','gamchig','A55A/04',True),  # ok area (1.73/1.23)\n",
    "    'GAULI':('GAULIGLETSCHER (Teilgl. von A54I/19n) Nr. 52','gaulig','A54I/05',True),  # ok (area 13.7/11.4)\n",
    "    'GELTEN':('GELTENGLETSCHER-W','gelteng-w','A56D/05',True),  # ok should receive the length changes from \"GELTEN\" entry\n",
    "    'GIETRO':('GIETRO GLACIER DU (Nr. 37)','gietro g du','B82/14',True),  # ok (area 5.54/5.16)\n",
    "    'GLAERNISCH':('GLÄRNISCHFIRN (Nr. 80)','glaernischfirn','A50K/04',True), # ok (area 2.09/1.41)\n",
    "    'GORNER':('GRENZGLETSCHER (Teilgl. von B56/07)','grenzg','B56/22n',True),  # problem: gorner not in Mauro's DB => it's named as \"Grenz\" there\n",
    "    'GRAND DESERT':('GRAND DESERT (Nendaz*) (Nr. 31)','grand desert','B75/06',True),  # ok area 1.85/1.06\n",
    "    'GRAND PLAN NEVE':('PLAN NEVE-E (Nr. 45)','plan neve-e','B17/03',True), # is plan neve-e (area 0.12/0.18) due to lat/lon of FoG point, elevation confirms\n",
    "    'GRIES':('GRIESGLETSCHER (Nr. 3)','griesg','B45/04',True),  # ok (area 4.83/4.78)\n",
    "    'GRIESS(KLAUSEN)':(['GRIESSFIRN-I (Nr. 74)','Griessfirn-II*'],['griessfirn-i','griessfirn-ii'],['A51C/02','A51C/01'],True),  # probably more:   and  \n",
    "    'GRIESSEN(OBWA.)':('GRIESSENFIRN','GRIESSENFIRN','A51H/02',True),  # ok (area 1.27/0.86)\n",
    "    'GRIESSERNU':('GRIESSERNU GLETSCHER','griessernu g','C02/06',True), # ok even though no area in FoG\n",
    "    'GROSSER ALETSCH':('GROSSER ALETSCH GLETSCHER (Teilgl. von B36/49n) Nr. 5','grosser aletsch g','B36/26',True), # ok (area 81.3/78.3)\n",
    "    'GRUBEN':(['GRÜEBUGLETSCHER-N-II (Teilgl. von B51/17n)','GRÜEBUGLETSCHER-S (Teilgl. von B51/17n)','GRÜEBUGLETSCHER-N-I  (Teilgl. von B51/17n)'],['grueebug-n-ii','grueebug-s','grueebug-n-i'],['B51/04','B51/05','B51/16n'],True), # ok area (1.32/(0.18+0.94+0.08)), NAME SHOULD  BE CHANGED IN FoG\n",
    "    'GUTZ':('GUTZGLETSCHER','gutzg','A54L/02',True),  # ok even though no area in FoG\n",
    "    'HANGENDE':('HANGENDE GLETSCHER','hangende g', 'B52/27',True), # ok due to lat/lon\n",
    "    'HINDRE SCHMADRI':('HINDRE SCHMADRIGLETSCHER','hindre schmadrig','A54M/16',True),  # ok no area in FoG\n",
    "    'HOHLAUB':(['Hohlaubgrat-E* (Teilgl. von B52/67n)','Hohlaub Gletscher* (Teilgl. von B52/67n)'],['hohlaubgrat-e','hohlaub g'],['B52/31','B52/32'],True), # both  and \n",
    "    'HOMATTU':(['HOMATTUGLETSCHER-II','HOMATTUGLETSCHER-I'],['homattug-ii','homattug-i'],['B47/05','C04/01'],True), # ok no area in FoG  \n",
    "    'HUEFI':('HÜFIFIRN (Nr. 73)','huefifirn','A51D/10',True),  # ok (area 13.73/12.72)\n",
    "    'KALTWASSER':('CHALTWASSERGLETSCHER (Nr. 7)','chaltwasserg','B47/04',True),  # ok (areas 18.5/1.49)\n",
    "    'KEHLEN':('CHELENGLETSCHER (Totalgl.; Nr. 68)','cheleng','A51F/15',True),  # ok even though area 1.73/3.15\n",
    "    'KESSJEN':('CHESSJENGLETSCHER-E (Nr. 12)','chessjeng-e','B52/33',True), #ok (areas 0.19/0.19) there is now chessjengl.-w!\n",
    "    'LAEMMERN (WILDSTRUBEL)':('WILDSTRUBELGLETSCHER (Teilgl. von A55C/24n) Nr. 63','wildstrubelg','A55C/13',True), # ok even though area 3.15/2.34\n",
    "    'LANG':('Langgletscher (Totalgl.; Nr. 18)','langg','B31/19n',True),  # ok areas 10.03/8.26\n",
    "    'LAVAZ':(['LAVAZ GLATSCHER DA (Nr. 82)','Lavaz-W*'],['lavaz glatscher da','lavaz-w'],['A14F/15','A14F/16'],True),  # ok area 1-76/(0.7+0.09)\n",
    "    'LENTA':('LÄNTAGLETSCHER (Nr. 84)','laentag','A14D/17',True),  # ok area 1.4/0.81\n",
    "    'LIMMERN':('LIMMERNFIRN (Nr. 78)','limmernfirn','A50I/06',True), # ok (area 2.41/1.89)\n",
    "    'LISCHANA':(['TRIAZZA VADRET DA'],['triazza v da'],['E02/05'],True),  # vadret da triazza is one of the two remnants (one is no longer mapped); LEAVE BRACKETS IN ORDER TO ASSIGN PARENT ID CORRECTLY!\n",
    "    'MAIGHELS EAST BRANCH':('MAIGHELS GLATSCHER DA-E','maighels glatscher da-e','A14I/04',True),  # ok but no area in FoG\n",
    "    'MAIGHELS WEST BRANCH':('MAIGHELS GLATSCHER DA-W','maighels glatscher da-w','A14I/05',True),  # ok but no area in FoG\n",
    "    'MARTINETS':('MARTINETS GLACIER DES (Nr. 46)','martinets g des','B17/08',True), # ok area 0.59/0.36\n",
    "    'MINSTIGER':('MINSTIGERGLETSCHER','minstigerg','B41/07',True),  # ok areas 3.09/2.25\n",
    "    'MITTELALETSCH':('MITTELALETSCHGLETSCHER (Teilgl. von B36/49n) Nr. 106','mittelaletschg','B36/21',True), # ok area 8.5/6.8\n",
    "    'MOIRY':('MOIRY GLACIER DE (Nr. 24)','moiry g de','B64/02',True), # ok area 6.11/4.89\n",
    "    'MOMING':('MOMING GLACIER DE (Nr. 23)','moming g de','B62/10',True),  # ok , maybe also Pointe Nord de Moming-SE* and Blanc de Moming-W*\n",
    "    'MONT DURAND':('MONT DURAND GLACIER DU (Nr. 35)','mont durand g du','B82/36',True),  # ok area 7.59/6.09\n",
    "    'MONT FORT (ZINAL)':(['PETIT M. FORT GLACIER DU','M. FORT GLACIER DU','Mont Fort-E*'],['petit m. fort g du','m. fort g du','mont fort-e'],['B75/07','B75/09','B75/16n'],True),  # not clear, probably PETIT M. FORT GLACIER DU (B75/07), but area is still too low\n",
    "    'MONT MINE':('MONT MINÉ GLACIER DU (Nr. 26)','mont mine g du','B72/15',True), # ok areas 10.3/9.9\n",
    "    'MONTO MORO GL.':('Monte Moro-W*','monte moro-w','B52/21',True),  # only a remnant obviously\n",
    "    'MORTERATSCH':('MORTERATSCH VADRET DA (Totalgl.; Nr. 94)','morteratsch v da','E22/03',True), # ok areas 17/15\n",
    "    'MURTEL':('MURTEL VADRET DAL','murtel v dal', 'E23/16',True),  # ok, NOT E24/04!!! \n",
    "    'MUTT':('MUTTGLETSCHER (Nr. 2)','muttg','B44/03',True), # ok, area 0.57/0.36\n",
    "    'MUTTEN':('Muttengletscher* (Teilgl. von A51E/23)','mutteng','A51E/56n',True), #ok, no areas in FoG\n",
    "    'OB.GRINDELWALD':('OBERER GRINDELWALDGLETSCHER (Nr. 57)','oberer grindelwaldg','A54L/04',True), # ok areas 10.07/8.41\n",
    "    'OBERAAR':('OBERAARGLETSCHER (Teilgl. von A54G/35n) Nr. 50','oberaarg','A54G/03',True), # ok areas 5.23/4.10\n",
    "    'OBERALETSCH':('OBERALETSCH GLETSCHER (Totalgl.; Nr. 6)','oberaletsch g','B36/01',True),  # ok areas 21/17\n",
    "    'OFENTAL':('OFENTAL GLETSCHER (Nr. 9)','ofental g','B52/17',True),  #ok even though areas 0.4/0.04...possibly one remnant missing in Mauro's DB (see swisstopo)\n",
    "    'OTEMMA':('Otemma (Teilgl. von B82/27)*','otemma','B82/51n',True),  # ok areas 16.55/12.59\n",
    "    'PALUE':('Palü Vadret da (Teilgl. von C93/04)','palue v da','C93/10n',True),  # ok areas 6.62/5.26\n",
    "    'PANEYROSSE':('PANEIROSSE GLACIER DE (Nr. 44)','paneirosse g de','B17/02',True),  # ok areas 0.45/0.3\n",
    "    'PARADIES':('PARADIESGLETSCHER (Nr. 86)','PARADIESGLETSCHER (Nr. 86)','A13N/06',True),  # ok 4.6/1.8\n",
    "    'PARADISINO (CAMPO)':('CAMP VEDREIT DA (Nr. 101)','camp vedreit da','C95/01',True),  # ok area 0.55/0.26\n",
    "    'PIERREDAR':('PIERREDAR GLACIER DE (Nr. 49)','pierredar g de','B16/05',True), # ok areas 0.67/0.3\n",
    "    'PIZOL':('PIZOLGLETSCHER (Nr. 81)','pizolg','A50D/01',True), # ok areas 0.32/0.08\n",
    "    'PLAINE MORTE':(['GLACIER DE LA PLAINE MORTE (Nr. 65)','PLAINE MORTE-W GLACIER DE LA','PLAINE MORTE-E GLACIER DE LA'],['g de la plaine morte','plaine morte-w g de la','plaine morte-e g de la'],['A55F/03','B23/09n','B24/04n'],True), # no area in FoG\n",
    "    'PLATTALVA':('GRIESSFIRN-N (Plattalva, Nr. 114)','griessfirn-n','A50I/07',True),  # ok area 0.71/0.33\n",
    "    'PORCHABELLA':('PORCHABELLA VADRET DA (Nr. 88)','porchabella v da','A12E/04',True),  # ok area 2.59/1.67\n",
    "    'PRAPIO':('PRAPIO GLACIER DU (Nr. 48)','prapio g du','B16/03',True),   # ok area 0.36/0.21\n",
    "    'PUNTEGLIAS':('Bündner Tödi*','buendner toedi','A14M/08',True),  #  sounds strange but ok area 0.93/0.67\n",
    "    'RHONE':('Rhonegletscher* (Teilgl. von B43/03)','rhoneg','B43/12n',True),  # ok areas 15.8/15.31\n",
    "    'RIED':('RIEDGLETSCHER (Nr. 17)','riedg','B54/03',True),  # ok areas 8.26/7.31\n",
    "    'ROSEG':('ROSEG VADRET DA (Nr. 92)','roseg v da','E23/11',True),  # ok areas 8.71/6.81\n",
    "    'ROSENLAUI':('ROSENLAUIGLETSCHER (Nr. 56)','rosenlauig','A54J/02',True),  # ok areas 5.9/5.4\n",
    "    'ROSSBODEN':('ROSSBODEGLETSCHER (Nr. 105)','rossbodeng','C02/04',True),  # ok areas 1.89/1.18\n",
    "    'ROTFIRN NORD':('Schattmigstock* (Rotfirn-N, Nr. 69)','schattmigstock','A51F/13',True),  #  ok area 1.21/0.91\n",
    "    'ROTTAL':('ROTTALGLETSCHER-NW (Teilgl. von B52/02)','rottalg-nw','B52/37n',True),  #  ok no area in FoG\n",
    "    'SALEINA':('Saleina* (Teilgl. von B85/16)','saleina','B85/29n',True),  # is , but area is too high (6.54) compared to FoG (5.03)\n",
    "    'SANKT ANNA':('ST. ANNAFIRN (Nr. 67)','st. annafirn','A51E/12',True),  # ok even though areas 0.41/0.22 (might be debris problem)\n",
    "    'SARDONA':('Sardonagletscher-II*','sardonag-ii','A15B/06n',True),  # should be Sardonagletscher-II*, but area is too high (0.45, FoG only 0.38)\n",
    "    'SCALETTA':('SCALETTAGLETSCHER (Nr. 115)','scalettag','A12D/03',True),  # ok even though area 0.66/0.21 (debris?)\n",
    "    'SCHOENBUEHL GL.':(['SCHÖNBÜHLGLETSCHER-SE','SCHÖNBÜHLGLETSCHER-NW'],['schoenbuehlg-se','schoenbuehlg-nw'],['B36/31','B36/56n'],True),  # FoG-D area (1957):1.43/(0.57+0.43)\n",
    "    'SCHWARZ':('SCHWARZGLETSCHER (Nr. 62)','schwarzg','A55C/05',True),  #  okay areas 1.6/1.09\n",
    "    'SCHWARZBACH':('SCHWARZBACHFIRN','schwarzbachfirn','A51E/08',True),  #  okay (not area in FoG)\n",
    "    'SCHWARZBERG':('Schwarzberggletscher* (Teilgl. von B52/24)','schwarzbergg','B52/63n',True),  #  ok area 5.17/5.33\n",
    "    'SESVENNA':('Sesvenna Vadret da-E (Teilgl. von E03/04)','sesvenna v da-e','E03/11n',True),  #  ok area 0.67/0.33\n",
    "    'SEEWJINEN':('SEEWJINEN GLETSCHER','seewjinen g','B52/22',True),  # ok no area in FoG\n",
    "    'SEX ROUGE':('SEX ROUGE GLACIER DU (Nr. 47)','sex rouge g du','B16/01',True), # ok even though area 0.72/0.27\n",
    "    'SILLERN':('SILLERE GLETSCHER','sillere g','A55B/11',True),  #  ok (no area in FoG)\n",
    "    'SILVRETTA':('SILVRETTAGLETSCHER (Nr. 90)','silvrettag','A10G/05',True),  # ok areas 2.74/2.67\n",
    "    'SIRWOLTE':('Griessernuhorn-N*','griessernuhorn-n','C03/04',True),  #should be Griessernuhorn-N* (c03/04) => NAME CHANGE IN FoG\n",
    "    'STEIN':('STEINGLETSCHER (Nr. 53)','steing','B47/01',True),  # ok even though area in Mauro's DB (5.68) slightly bigger than in FoG (5.6)\n",
    "    'STEINLIMMI':('STEINLIMIGLETSCHER (Nr. 54)','steinlimig','A54E/13',True),  # ok areas 2.21/1.59\n",
    "    'SULZ':('HINTERSULZFIRN (Nr. 79)','hintersulzfirn','A50I/02',True),  #  must be HINTERSULZFIRN (Nr. 79), A50I/02,  (lat/lon), but area is bigger (0.26) than in FoG (0.2)\n",
    "    'SURETTA':(['SURETTAGLETSCHER-E (Piz Por*)','SURETTAGLETSCHER-W (Hauptgl., Nr. 87)'],['surettag-e','surettag-w'],['A13I/01','A13I/02'],True), # must be ,  and maybe also Suretta Lückli*. FoG point unclear\n",
    "    'TIATSCHA':('TIATSCHA VADRET (La Cudera, Nr. 96)','tiatscha v','E50/07',True), # okay areas 2.11/1.82\n",
    "    'TIEFEN':('TIEFENGLETSCHER (Nr. 66)','tiefeng','A51E/37', True), # ok even though area 3.17/1.99\n",
    "    'TOURNELON BLANCE':(['Tournelon Blanc-SE*','Tournelon Blanc-E*','Tournelon Blanc-NE*','Col du Tournelon Blanc*'],['tournelon blanc-se','tournelon blanc-e','tournelon blanc-ne','col du tournelon blanc'],['B82/42','B82/43','B82/44','B82/53n'],True),  # defined as given polygons as only special event in FoG \n",
    "    'TRIENT':('TRIENT GLACIER DU (Nr. 43)','trient g du','B90/02',True),  # ok area 6.58/5.82\n",
    "    'TRIEST GL.':('DRIESTGLETSCHER','driestg','B36/17',True),  # ok no area in FoG\n",
    "    'TRIFT (GADMEN)':('TRIFTGLETSCHER (Nr. 55)','triftg','A54E/24',True),  # ok area 15.33/14.9\n",
    "    'TSANFLEURON':('TSANFLEURON GLACIER DE (Nr. 33)','tsanfleuron g de','B22/01',True),  # ok area 3.78/2.64\n",
    "    'TSCHIERVA':(['TSCHIERVA VADRETTIN DA','TSCHIERVA VADRET DA (Nr. 93)'],['tschierva vtin da','tschierva v da'],['E23/04','E23/06'],True),  # area is 6.83/(0.4+5.81); FoG lat/lon suggests to include also the vadrettin\n",
    "    'TSCHINGEL':(['TSCHINGELFIRN (Nr. 60)','Tschingelspitz-S*','Tschingelgrat-S*'],['tschingelfirn','tschingelspitz-s','tschingelgrat-s'],['A54M/21','A54M/51n','A54M/52n'],True),  # area 6.18/(5.22+0.01+0.006)\n",
    "    'TSEUDET':('TSEUDET GLACIER DE (Nr. 40)','tseudet g de','B84/17',True),  # ok area 1.76/1.43\n",
    "    'TSIDJIORE NOUVE':('TSIJIORE NOUVE GLACIER DE (Nr. 28)','tsijiore nouve g de','B73/16',True), # ok even though area 3.12/2.72\n",
    "    'TURTMANN (WEST)':('TURTMANNGLETSCHER (Teilgl. von B60/09)','turtmanng','B60/21n',True),  # chaos in FoG: sometimes brunegggletscher is included in turtmanngletscher (see state table). TURTMANNGLETSCHER (Teilgl. von B60/09) is only about half (5.5) of turtmann-w in FoG (11km2)\n",
    "    'UNT.GRINDELWALD':(['OBERS ISCHMEER (Teilgl. von A54L/19)','FIESCHERGLETSCHER BE (Teilgl. von A54L/19)'],['obers ischmeer','fiescherg be'],['A54L/31n','A54L/36n'],True),  # leave Unt. Grindelw. and make it parent\n",
    "    'UNTERAAR':('UNTERAARGLETSCHER (Teilgl.von A54G/50n) Nr. 51','unteraarg','A54G/11',True), # ok area 22.7/22.5\n",
    "    'VAL TORTA':('VALTORTA VADRET','valtorta v','E46/06',True),  # ok area 0.17/0.06\n",
    "    'VALLEGGIA':('VALLEGGIA GH. DI (Nr. 117)','valleggia gh. di','C33/08',True),  # ok area 0.59/0.30\n",
    "    'VALSOREY':('Valsorey (Teilgl. von B84/15)*','valsorey','B84/27n',True),  #  ok area 2.34/1.9\n",
    "    'VERSTANKLA':('Verstanclagletscher (Teilgl. von A10G/08)','verstanclag','A10G/24n',True), #ok area 1.06/0.71\n",
    "    'VORAB':('VORAB GLATSCHER DIL (Nr. 85)','vorab glatscher dil','A14P/01',True), # ok area 2.51/1.22, could also be Vorabsattel-W* (but drain ins other valley)\n",
    "    'VORDRE SCHMADRI':('VORDRE SCHMADRIGLETSCHER','vordre schmadrig','A54M/15',True),  # ok no area in FoG\n",
    "    'WALLENBUR':('WALLENBURFIRN (Nr. 71)','wallenburf','A51F/24',True), # ok area 1.7/1.41\n",
    "    'WANNENHORN GL. N':('WANNENHORNGLETSCHER-NW (Teilgl. von B36/57n)','wannenhorng-nw','B36/32',True), # must be this one due to FoG lat/lon\n",
    "    'WANNENHORN GL. S':('WANNENHORNGLETSCHER-SE (Teilgl. von B36/57n)','wannenhorng-se','B36/33',True), # must be this one due to FoG lat/lon\n",
    "    'WITENWASSEREN':('WITENWASSERENGLETSCHER','witenwassereng','A51E/20',True), # no FoG area given....(could also include Witenwasseren-W*, but drains in another valley)\n",
    "    'ZENBAECHEN GL.':('ZENBAECHENGLETSCHER','zenbaecheng','B36/18',True), # no FoG area given\n",
    "    'ZINAL':('ZINAL GLACIER DE (Nr. 22)','zinal g de','B63/05',True),  # ok area 16/13.3 \n",
    "    'ZMUTT':('ZMUTTGLETSCHER (Nr. 15)','zmuttg','B57/05',True),  # ok area 17.4/13.7    \n",
    "}\n",
    "\n",
    "# removed:\n",
    "# 'WANNENHORN GL.':('','','',False),  # is only parent glacier, parent IDs for S/N already present, so can be deleted from dict\n",
    "# 'TAELLIBODEN':('','','',False),  # no longer digitized in Mauro's inventory => seems to be totally disappeared on orthophoto\n",
    "# 'RAETZLI (PLAINE MORTE)':('GLACIER DE LA PLAINE MORTE (Nr. 65)','g de la plaine morte','A55F/03',True),  # more or less the same as PLAINE MORTE, min_elevation in PDB except for confusing entry by Huss 2011\n",
    "# 'FLUCHTHORN GL.':('','','', False), # should be Fluchthorn-NE* B52/26 and maybe also Fluchthorn-E* B52/25 (area 0.37/(0.26+0.01)); problem is hangender ferner inbetween; is taken out due to Michi's suggestion to keep old glacier (unknown which it is and include a duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin to establish new dataset containing the columns from the CHANGE file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Determine which glaciers glaciers are already in FoG, which are problematic and which need a new ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n",
      "True\n",
      "0\n",
      "187\n",
      "1232\n"
     ]
    }
   ],
   "source": [
    "take_over_id = {}                                    # those glaciers that can take over a FoG ID\n",
    "problems = {}                                        # those glaciers where it is unclear whether they can take over an ID \n",
    "new_id = pdfll.Glacier_name_SGI2010.values.tolist()  # those glaciers from Mauro's DB that need a new ID (all - (take_over_id + problems))\n",
    "\n",
    "print(len(new_id))\n",
    "print('A54E/24' in new_id)\n",
    "for key,value in links.items():\n",
    "    # assign take over/problems\n",
    "    if value[-1] == True:\n",
    "        take_over_id[key] = value\n",
    "    else:\n",
    "        problems[key] = value\n",
    "        \n",
    "    # check which still need a new ID\n",
    "    if value[-1] == True: \n",
    "        if isinstance(value[-2], str):\n",
    "            new_id.remove(value[-2])\n",
    "        elif isinstance(value[-2], list):\n",
    "            pass\n",
    "            for element in value[-2]:\n",
    "                new_id.remove(element)\n",
    "        else:\n",
    "            raise ValueError('%s neither list nor string' % value[-2])\n",
    "        \n",
    "        \n",
    "print(sum([len(problems[key][-2]) for key,value in problems.items()])) # sum of all SGI2010 short names => should be zero for problems\n",
    "print(sum([len(take_over_id[key][-2]) if isinstance(take_over_id[key][-2],list) else 1 for key,value in take_over_id.items()])) # # sum of all SGI2010 short names\n",
    "print(len(new_id)) # sum of all SGI2010 short names that need a new ID in FoG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTENTION: As long as not all problems are solved, we generate too many new IDs!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some new raw DataFrames and adjust columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pda = pd.DataFrame(columns=pda.columns.values)\n",
    "new_pdb = pd.DataFrame(columns=pdb.columns.values)\n",
    "new_pdd = pd.DataFrame(columns=pdd.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_pda = new_pda[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'RIVER_BASIN', 'FREE_POSITION',\n",
    "                                   'LOCAL_CODE', 'LOCAL_PSFG', 'GEN_LOCATION', 'SPEC_LOCATION', 'LATITUDE', 'LONGITUDE', \n",
    "                                   'PRIM_CLASSIFIC', 'FORM', 'FRONTAL_CHARS', 'EXPOS_ACC_AREA', 'EXPOS_ABL_AREA', \n",
    "                                   'PARENT_GLACIER', 'REMARKS']]#, 'GEO-REGION_CODE', 'GEO-SUBREGION_CODE', 'AREA']]\n",
    "\n",
    "new_pdb = new_pdb[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'HIGHEST_ELEVATION','MEDIAN_ELEVATION', \n",
    "                                   'LOWEST_ELEVATION', 'ELEVATION_UNC', 'LENGTH', 'LENGTH_UNC', 'AREA', 'AREA_UNC', \n",
    "                                   'SURVEY_DATE', 'SURVEY_PLATFORM_METHOD', 'INVESTIGATOR', 'SPONS_AGENCY', \n",
    "                                   'REFERENCE', 'REMARKS']]\n",
    "\n",
    "new_pdd = new_pdd[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'LOWER_BOUND','UPPER_BOUND', \n",
    "                                   'AREA_SURVEY_YEAR', 'AREA_CHANGE', 'AREA_CHANGE_UNC', 'THICKNESS_CHG', \n",
    "                                   'THICKNESS_CHG_UNC', 'VOLUME_CHANGE', 'VOLUME_CHANGE_UNC', 'SURVEY_DATE', \n",
    "                                   'SD_PLATFORM_METHOD', 'REFERENCE_DATE', 'RD_PLATFORM_METHOD', \n",
    "                                   'INVESTIGATOR', 'SPONS_AGENCY', 'REFERENCE', 'REMARKS']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some new arbitrary IDs, beginning at given number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin_new_id = 4585  # where to start with assigning new WGMS IDs\n",
    "new_id_range = list(range(begin_new_id, begin_new_id+len(pdf)+1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some correction rules to transform Mauro's names to FoG names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_adjust_FoG = {'gletscher':'', 'ferner':'','gh.':'ghiacciaio', 'gl.':'','teilgl. von':'part of', 'teil ':'part ', ' von ':' of ', '*':'', 'nr.':'no.', 'haupt':'main', 'zus\\'gesetzt':'combined', 'nur fläche':'only area', 'nur':'only', 'flaeche':'area', 'sammler':'group of glacierets', 'ost':'e','nord':'n','ä':'ae', 'ö':'oe', 'ü':'ue', 'é':'e', 'à':'a', 'è':'e', 'ô':'o', 'ß':'ss'} # 'firn':'',\n",
    "hot_list = ['glacier', 'vadret', 'ghiacciaio', 'vedretta', 'glatscher', 'vadret', 'vadrec.'] # vadrec. is important as also 'vadrecc' appears (regex search) \n",
    "special_names ={'GLACIER DE LA PLAINE MORTE (Nr. 65)':'PLAINE MORTE, GLACIER DE LA',\n",
    "             'PLAINE MORTE-W GLACIER DE LA':'PLAINE MORTE GLACIER DE LA-W',\n",
    "             'PLAINE MORTE-E GLACIER DE LA':'PLAINE MORTE GLACIER DE LA-E'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to convert Mauro's name to FoG format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def name_to_FoG(name, replace_dict, hot_list, special_names):\n",
    "    \n",
    "    # check if it is a very special name\n",
    "    if name in special_names.keys():\n",
    "        return special_names[name]\n",
    "    \n",
    "    # to make it easier comparable\n",
    "    name = name.lower()\n",
    "    \n",
    "    # replace some predefined stuff\n",
    "    for key in replace_dict.keys():\n",
    "        #key_regex = re.compile(key)\n",
    "        #if 'teil' in name:\n",
    "        #    print(name)\n",
    "        if key in name:\n",
    "        #if re.match(key_regex, name):\n",
    "            name = name.replace(key, replace_dict[key])\n",
    "        #print(name)\n",
    "    \n",
    "    # replace the bracket stuff\n",
    "    #start = name.find('(')\n",
    "    #if start != -1:\n",
    "    #    name = name[0:start]\n",
    "    #name = name.replace('*', '')\n",
    "    #name = name.strip()\n",
    "    \n",
    "    # if the name is already sorted in the desired way (e.g. 'lai blau glatscher dil'), insert a comma as specified by Michi\n",
    "    \n",
    "    \n",
    "    # reorder the words\n",
    "    splitname = name.split(' ')\n",
    "    if len(splitname) >= 3:\n",
    "        for hotname in hot_list:\n",
    "            hotname_regex = re.compile(hotname)  # regex search due to \"vadrecc\" problem\n",
    "            if re.match(hotname_regex, name) and len(splitname)>1:\n",
    "                print(name, hotname,splitname)\n",
    "                try:\n",
    "                    resort_ix = splitname.index(hotname)\n",
    "                except:\n",
    "                    resort_ix = splitname.index(hotname_regex)\n",
    "                if resort_ix == 0: # e.g. \"glacier de BLA\"\n",
    "                    name = splitname[-1]+', '+' '.join(splitname[:-2])\n",
    "                    print(name)\n",
    "                elif resort_ix == 1: # e.g. \"BLA glacier de\"\n",
    "                    name = splitname[0]+', '+' '.join(splitname[1:])\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    # strip name (there might be spaces from string rebuilding)\n",
    "    name = name.strip()\n",
    "    return name.upper()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants that can be inserted glacier-independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some constants\n",
    "POL_UNIT = 'CH'\n",
    "RGI_REGION = 'Central Europe'\n",
    "RGI_SUBREGION = 'Alps'\n",
    "MISS_VAL = 9999\n",
    "SD_PLATFORM_METHOD = 'aC'\n",
    "RD_PLATFORM_METHOD = 'aC'\n",
    "SD_METHOD = 'PL'\n",
    "RD_METHOD = 'M'\n",
    "REFERENCE = 'Fischer et al. (2014); Arctic, Antarctic and Alpine Research, 46(4), pp.933-945'\n",
    "AGENCY = 'Department of Geosciences, University of Fribourg, 1700 Fribourg, Switzerland'\n",
    "INVESTIGATOR = 'Fischer et al.'\n",
    "PUB_DATE = int(2016)\n",
    "LENGTH_UNC_FACTOR = 0.05   # actually 2-5%, but specification says \"maximum\" error\n",
    "# ELEV_UNC = 3.0   # vertical accuracy 1-3m for swissimage (see Fischer et al. 2014); not used as also digitizing error and terrain steepness plays a role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to determine the area uncertainty (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def area_unc(area):\n",
    "    AREA_UNC_FACTOR_S = 0.076  # for Small glaciers (<1km2)\n",
    "    AREA_UNC_FACTOR_M = 0.047  # for Medium glaciers (1-5km2)\n",
    "    AREA_UNC_FACTOR_L = 0.076  # for Large glaciers (>5km2)\n",
    "    \n",
    "    if area <1.:\n",
    "        area_uncert = area * AREA_UNC_FACTOR_S\n",
    "    elif 1. <= area <= 5.:\n",
    "        area_uncert = area * AREA_UNC_FACTOR_M\n",
    "    elif area > 5.:\n",
    "        area_uncert = area * AREA_UNC_FACTOR_L\n",
    "    return area_uncert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create new entries with ID already in FoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_entries_id_present(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, take_over_dict, new_ids):\n",
    "\n",
    "    for key,val in take_over_id.items():\n",
    "\n",
    "        # two new DFs for the different FoG files\n",
    "        glacier_pdd = pd.DataFrame(columns=new_pdd.columns.values)\n",
    "        glacier_pda = pd.DataFrame(columns=new_pda.columns.values)\n",
    "        glacier_pdb = pd.DataFrame(columns=new_pdb.columns.values)\n",
    "\n",
    "        # present WGMS ID\n",
    "        gid = pda[pda.NAME == key].WGMS_ID.values[0]\n",
    "\n",
    "        # Mauros glaciers entry: \n",
    "        if isinstance(val[-2], str): # if there is only one equivalent: fill only PDB and PDD and leave PDA as it is\n",
    "            mg = pdf[pdf.Code_SGI2010 == val[-2]]\n",
    "            mg_ll = pdfll[pdfll.Glacier_name_SGI2010 == val[-2]]\n",
    "            \n",
    "            # set the REMARKS (added at the end)\n",
    "            REMARKS_pdd = ''\n",
    "            REMARKS_pdb = ''\n",
    "\n",
    "            if not mg.empty:\n",
    "                glacier_pdd.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                glacier_pdd.loc[gid, 'NAME'] = pda[pda.WGMS_ID == gid].NAME.iloc[0]\n",
    "                glacier_pdd.loc[gid, 'WGMS_ID'] = gid\n",
    "                glacier_pdd.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                glacier_pdd.loc[gid, 'LOWER_BOUND'] = MISS_VAL\n",
    "                glacier_pdd.loc[gid, 'UPPER_BOUND'] = MISS_VAL\n",
    "                glacier_pdd.loc[gid, 'AREA_SURVEY_YEAR'] = round(mg.area_t2_km2.iloc[0],3)\n",
    "                glacier_pdd.loc[gid, 'AREA_CHANGE'] = round(mg.area_t2_km2.iloc[0] - mg.area_t1_km2.iloc[0]) * 1000  # *1000: unit difference (1000m2 and km2)\n",
    "                #glacier_pdd.loc[gid, 'AREA_CHANGE_UNC'] = round((area_unc(mg.area_t1_km2.iloc[0]) + area_unc(mg.area_t2_km2.iloc[0]))* 1000, 2)  # error is addition of both errors for t1 and t2 in worst case; *1000 for unit\n",
    "                glacier_pdd.loc[gid, 'THICKNESS_CHG'] = round(((mg.dvol_mio_m3_between_t1_and_t2.iloc[0] * 10**6) / ((mg.area_t2_km2.iloc[0] + mg.area_t1_km2.iloc[0]) * 0.5 * 10**6)) * 1000, -1) # *1000 for conversion from m thickness change to mm change\n",
    "                #glacier_pdd.loc[gid, 'THICKNESS_CHG_UNC'] = np.nan  # berechnen? AREA_UNC fehlt und der Fehler durch Mittelung\n",
    "                glacier_pdd.loc[gid, 'VOLUME_CHANGE'] = round(mg.dvol_mio_m3_between_t1_and_t2.iloc[0] *1000)   # *1000: unit difference (1000m3 / 1000000m3)\n",
    "                glacier_pdd.loc[gid, 'VOLUME_CHANGE_UNC'] = round(mg.uncertainty_dvol_between_t1_and_t2_mio_m3.iloc[0]) # *1000:unit difference (1000m3 / 1000000m3)\n",
    "                glacier_pdd.loc[gid, 'SURVEY_DATE'] = int(mg.t2_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                glacier_pdd.loc[gid, 'SD_PLATFORM_METHOD'] = SD_PLATFORM_METHOD # must be determined\n",
    "                REMARKS_pdd = REMARKS_pdd + ' Survey date method: %s.' % SD_METHOD\n",
    "                glacier_pdd.loc[gid, 'REFERENCE_DATE'] = int(mg.t1_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                glacier_pdd.loc[gid, 'RD_PLATFORM_METHOD'] = RD_PLATFORM_METHOD   # must be determined\n",
    "                REMARKS_pdd = REMARKS_pdd + ' Reference date method: %s.' % RD_METHOD\n",
    "                #glacier_pdd.PUB_IN_FOG = PUB_DATE      # not needed in data submission form\n",
    "                glacier_pdd.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                glacier_pdd.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                glacier_pdd.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                REMARKS_pdd = REMARKS_pdd + ' ID SGI 1973: %s.' % mg.ID_SGI1973.iloc[0]\n",
    "                REMARKS_pdd = REMARKS_pdd + ' ID SGI 2010: %s.' % mg.Code_SGI2010.iloc[0]\n",
    "                # at the very end \n",
    "                glacier_pdd.loc[gid, 'REMARKS'] = REMARKS_pdd\n",
    "                \n",
    "                new_pdd = pd.concat([new_pdd, glacier_pdd], ignore_index=True)\n",
    "\n",
    "                \n",
    "                # fill PDB                                           \n",
    "                glacier_pdb.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                glacier_pdb.loc[gid, 'NAME'] = pda[pda.WGMS_ID == gid].NAME.iloc[0]\n",
    "                glacier_pdb.loc[gid, 'WGMS_ID'] = gid\n",
    "                glacier_pdb.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                glacier_pdb.loc[gid, 'HIGHEST_ELEVATION'] = mg_ll['max_elevation (masl)'].iloc[0]\n",
    "                glacier_pdb.loc[gid, 'MEDIAN_ELEVATION'] = mg_ll['median_elevation (masl)'].iloc[0]\n",
    "                glacier_pdb.loc[gid, 'LOWEST_ELEVATION'] = mg_ll['min_elevation (masl)'].iloc[0]\n",
    "                #glacier_pdb.loc[gid, 'ELEVATION_UNC'] = np.nan\n",
    "                glacier_pdb.loc[gid, 'LENGTH'] = round(mg_ll['length (km)'].iloc[0],2)\n",
    "                #glacier_pdb.loc[gid, 'LENGTH_UNC'] = round(mg_ll['length (km)'].iloc[0] * LENGTH_UNC_FACTOR, -1)  # round to next ten meters\n",
    "                glacier_pdb.loc[gid, 'AREA'] = round(mg_ll['area(km2)'].iloc[0],3)\n",
    "                #glacier_pdb.loc[gid, 'AREA_UNC'] = round(area_unc(mg.area_t1_km2.iloc[0]), 2)  # round to 0.01km2\n",
    "                glacier_pdb.loc[gid, 'SURVEY_DATE'] = mg_ll.year.iloc[0]\n",
    "                glacier_pdb.loc[gid, 'SURVEY_PLATFORM_METHOD'] = SD_PLATFORM_METHOD\n",
    "                REMARKS_pdb = REMARKS_pdb + ' Survey date method: %s.' % SD_METHOD\n",
    "                glacier_pdb.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                glacier_pdb.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                glacier_pdb.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                glacier_pdb.loc[gid, 'REMARKS'] = REMARKS_pdb\n",
    "                                                           \n",
    "                new_pdb = pd.concat([new_pdb, glacier_pdb], ignore_index=True)\n",
    "\n",
    "                                                           \n",
    "        elif isinstance(val[-2], list):  ## multiple polygons with PARENT_GLACIER\n",
    "\n",
    "            for sgiid in val[-2]:\n",
    "\n",
    "                # Mauro's glacier\n",
    "                mg = pdf[pdf.Code_SGI2010 == sgiid]\n",
    "                mg_ll = pdfll[pdfll.Glacier_name_SGI2010 == sgiid]\n",
    "\n",
    "                # Parent glacier ID\n",
    "                pg_id = gid\n",
    "                # new ID for the entries themselves and pop the index so that it is not used twice\n",
    "                new_id = new_ids[0]\n",
    "                new_ids.pop(0)\n",
    "\n",
    "\n",
    "                # set the REMARKS (added at the end)\n",
    "                REMARKS_pdd = ''\n",
    "                REMARKS_pda = ''\n",
    "                REMARKS_pdb = ''\n",
    "\n",
    "                if not mg.empty:\n",
    "                    glacier_pdd.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                    glacier_pdd.loc[gid, 'NAME'] = name_to_FoG(mg.Glacier_name_SGI2010.iloc[0], name_adjust_FoG, hot_list, special_names)\n",
    "                    glacier_pdd.loc[gid, 'WGMS_ID'] = new_id\n",
    "                    glacier_pdd.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                    glacier_pdd.loc[gid, 'LOWER_BOUND'] = MISS_VAL\n",
    "                    glacier_pdd.loc[gid, 'UPPER_BOUND'] = MISS_VAL\n",
    "                    glacier_pdd.loc[gid, 'AREA_SURVEY_YEAR'] = round(mg.area_t2_km2.iloc[0],3)\n",
    "                    glacier_pdd.loc[gid, 'AREA_CHANGE'] = round((mg.area_t2_km2.iloc[0] - mg.area_t1_km2.iloc[0]) * 1000)  # *1000: unit difference (1000m2 and km2)\n",
    "                    #glacier_pdd.loc[gid, 'AREA_CHANGE_UNC'] = round((area_unc(mg.area_t1_km2.iloc[0]) + area_unc(mg.area_t2_km2.iloc[0]))* 1000, -1)  # error is addition of both errors for t1 and t2 in worst case; *1000 for unit\n",
    "                    glacier_pdd.loc[gid, 'THICKNESS_CHG'] = round(((mg.dvol_mio_m3_between_t1_and_t2.iloc[0] * 10**6) / ((mg.area_t2_km2.iloc[0] + mg.area_t1_km2.iloc[0]) * 0.5 * 10**6)) * 1000) # *1000 for conversion from m thickness change to mm change\n",
    "                    #glacier_pdd.loc[gid, 'THICKNESS_CHG_UNC'] = np.nan  # berechnen? AREA_UNC fehlt und der Fehler durch Mittelung\n",
    "                    glacier_pdd.loc[gid, 'VOLUME_CHANGE'] = round(mg.dvol_mio_m3_between_t1_and_t2.iloc[0] *1000)   # *1000: unit difference (1000m3 / 1000000m3)\n",
    "                    glacier_pdd.loc[gid, 'VOLUME_CHANGE_UNC'] = round(mg.uncertainty_dvol_between_t1_and_t2_mio_m3.iloc[0]) # *1000:unit difference (1000m3 / 1000000m3)\n",
    "                    glacier_pdd.loc[gid, 'SURVEY_DATE'] = int(mg.t2_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                    glacier_pdd.loc[gid, 'SD_PLATFORM_METHOD'] = SD_PLATFORM_METHOD # must be determined\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' Survey date method: %s.' % SD_METHOD\n",
    "                    glacier_pdd.loc[gid, 'REFERENCE_DATE'] = int(mg.t1_year.iloc[0] *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "                    glacier_pdd.loc[gid, 'RD_PLATFORM_METHOD'] = RD_PLATFORM_METHOD   # must be determined\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' Reference date method: %s.' % RD_METHOD\n",
    "                    #glacier_pdd.PUB_IN_FOG = PUB_DATE      # not needed in data submission form\n",
    "                    glacier_pdd.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                    glacier_pdd.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                    glacier_pdd.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' ID SGI 1973: %s.' % mg.ID_SGI1973.iloc[0]\n",
    "                    REMARKS_pdd = REMARKS_pdd + ' ID SGI 2010: %s.' % mg.Code_SGI2010.iloc[0]\n",
    "                    # at the very end \n",
    "                    glacier_pdd.loc[gid, 'REMARKS'] = REMARKS_pdd\n",
    "\n",
    "                    new_pdd = pd.concat([new_pdd, glacier_pdd], ignore_index=True)\n",
    "                                                               \n",
    "                                                               \n",
    "                    # Fill PDB\n",
    "                    glacier_pdb.loc[gid, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "                    glacier_pdb.loc[gid, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0], name_adjust_FoG, hot_list, special_names)\n",
    "                    glacier_pdb.loc[gid, 'WGMS_ID'] = new_id\n",
    "                    glacier_pdb.loc[gid, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'HIGHEST_ELEVATION'] = mg_ll['max_elevation (masl)'].iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'MEDIAN_ELEVATION'] = mg_ll['median_elevation (masl)'].iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'LOWEST_ELEVATION'] = mg_ll['min_elevation (masl)'].iloc[0]\n",
    "                    #glacier_pdb.loc[gid, 'ELEVATION_UNC'] = np.nan\n",
    "                    glacier_pdb.loc[gid, 'LENGTH'] = round(mg_ll['length (km)'].iloc[0], 2)\n",
    "                    #glacier_pdb.loc[gid, 'LENGTH_UNC'] = mg_ll['length (km)'].iloc[0] * LENGTH_UNC_FACTOR\n",
    "                    glacier_pdb.loc[gid, 'AREA'] = round(mg_ll['area(km2)'].iloc[0],3)\n",
    "                    #glacier_pdb.loc[gid, 'AREA_UNC'] = round(area_unc(mg.area_t1_km2.iloc[0]), 2)\n",
    "                    glacier_pdb.loc[gid, 'SURVEY_DATE'] = mg_ll.year.iloc[0]\n",
    "                    glacier_pdb.loc[gid, 'SURVEY_PLATFORM_METHOD'] = SD_PLATFORM_METHOD\n",
    "                    REMARKS_pdb = REMARKS_pdb + ' Survey date method: %s.' % SD_METHOD\n",
    "                    glacier_pdb.loc[gid, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "                    glacier_pdb.loc[gid, 'SPONS_AGENCY'] = AGENCY\n",
    "                    glacier_pdb.loc[gid, 'REFERENCE'] = REFERENCE\n",
    "                    glacier_pdb.loc[gid, 'REMARKS'] = REMARKS_pdb\n",
    "\n",
    "                    new_pdb = pd.concat([new_pdb, glacier_pdb], ignore_index=True)\n",
    "\n",
    "\n",
    "                if not mg_ll.empty:\n",
    "                    glacier_pda.loc[gid, 'POLTITICAL_UNIT'] = POL_UNIT\n",
    "                    glacier_pda.loc[gid, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "                    glacier_pda.loc[gid, 'WGMS_ID'] = new_id \n",
    "                    glacier_pda.loc[gid, 'LATITUDE'] = round(mg_ll['y WGS84)'].iloc[0], 6)\n",
    "                    glacier_pda.loc[gid, 'LONGITUDE'] = round(mg_ll['Location(x WGS84)'].iloc[0], 6)\n",
    "                    glacier_pda.loc[gid, 'REGION'] = RGI_REGION\n",
    "                    glacier_pda.loc[gid, 'SUBREGION'] = RGI_SUBREGION\n",
    "                    glacier_pda.loc[gid, 'PARENT_GLACIER'] = pg_id\n",
    "                    glacier_pda.loc[gid, 'SGI_2010_ID'] = sgiid\n",
    "\n",
    "                new_pda = pd.concat([new_pda, glacier_pda], ignore_index=True)\n",
    "\n",
    "    return new_pda, new_pdb, new_pdd, new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glacier de la plaine morte (no. 65) glacier ['glacier', 'de', 'la', 'plaine', 'morte', '(no.', '65)']\n",
      "65), glacier de la plaine morte\n"
     ]
    }
   ],
   "source": [
    "new_pda, new_pdb, new_pdd, new_id_range = create_entries_id_present(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, take_over_id, new_id_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create entries with ID that has to be introduced into FoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_entries_new_id(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, new_id_list, new_ids):\n",
    "\n",
    "    for id_2010 in new_id_list:\n",
    "\n",
    "        # two new DFs for the different FoG files\n",
    "        glacier_pdd = pd.DataFrame(columns=new_pdd.columns.values)\n",
    "        glacier_pda = pd.DataFrame(columns=new_pda.columns.values)\n",
    "        glacier_pdb = pd.DataFrame(columns=new_pdb.columns.values)\n",
    "\n",
    "        # Mauro's entry: \n",
    "        mg = pdf[pdf.Code_SGI2010 == id_2010]\n",
    "        mg_ll = pdfll[pdfll.Glacier_name_SGI2010 == id_2010]\n",
    "        \n",
    "        # new ID for the entries themselves and pop the index so that it is not used twice\n",
    "        new_id = new_ids[0]\n",
    "        new_ids.pop(0)\n",
    "\n",
    "        # set the REMARKS (added at the end)\n",
    "        REMARKS_pdd = ''\n",
    "        REMARKS_pdb = ''\n",
    "\n",
    "        glacier_pda.loc[new_id, 'POLTITICAL_UNIT'] = POL_UNIT\n",
    "        glacier_pda.loc[new_id, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "        glacier_pda.loc[new_id, 'WGMS_ID'] = int(new_id) \n",
    "        glacier_pda.loc[new_id, 'LATITUDE'] = round(mg_ll['y WGS84)'].iloc[0], 6)\n",
    "        glacier_pda.loc[new_id, 'LONGITUDE'] = round(mg_ll['Location(x WGS84)'].iloc[0], 6)\n",
    "        glacier_pda.loc[new_id, 'REGION'] = RGI_REGION\n",
    "        glacier_pda.loc[new_id, 'SUBREGION'] = RGI_SUBREGION\n",
    "        glacier_pda.loc[new_id, 'SGI_2010_ID'] = id_2010\n",
    "\n",
    "        new_pda = pd.concat([new_pda, glacier_pda], ignore_index=True)\n",
    "\n",
    "\n",
    "        if not mg.empty:\n",
    "            glacier_pdd.loc[new_id, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "            glacier_pdd.loc[new_id, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "            glacier_pdd.loc[new_id, 'WGMS_ID'] = new_id\n",
    "            glacier_pdd.loc[new_id, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "            glacier_pdd.loc[new_id, 'LOWER_BOUND'] = MISS_VAL\n",
    "            glacier_pdd.loc[new_id, 'UPPER_BOUND'] = MISS_VAL\n",
    "            glacier_pdd.loc[new_id, 'AREA_SURVEY_YEAR'] = round(mg.area_t2_km2.iloc[0],3)\n",
    "            glacier_pdd.loc[new_id, 'AREA_CHANGE'] = round((mg.area_t2_km2.iloc[0] - mg.area_t1_km2.iloc[0]) * 1000)  # *1000: unit difference (1000m2 and km2)\n",
    "            #glacier_pdd.loc[new_id, 'AREA_CHANGE_UNC'] = round((area_unc(mg.area_t1_km2.iloc[0]) + area_unc(mg.area_t2_km2.iloc[0]))* 1000, -1)  # error is addition of both errors for t1 and t2 in worst case; *1000 for unit\n",
    "            glacier_pdd.loc[new_id, 'THICKNESS_CHG'] = round(((mg.dvol_mio_m3_between_t1_and_t2.iloc[0] * 10**6) / ((mg.area_t2_km2.iloc[0] + mg.area_t1_km2.iloc[0]) * 0.5 * 10**6)) * 1000) # *1000 for conversion from m thickness change to mm change\n",
    "            #glacier_pdd.loc[new_id, 'THICKNESS_CHG_UNC'] = np.nan  # berechnen? AREA_UNC fehlt und der Fehler durch Mittelung\n",
    "            glacier_pdd.loc[new_id, 'VOLUME_CHANGE'] = round(mg.dvol_mio_m3_between_t1_and_t2.iloc[0] *1000)   # *1000: unit difference (1000m3 / 1000000m3)\n",
    "            glacier_pdd.loc[new_id, 'VOLUME_CHANGE_UNC'] = round(mg.uncertainty_dvol_between_t1_and_t2_mio_m3.iloc[0]) # *1000:unit difference (1000m3 / 1000000m3)\n",
    "            glacier_pdd.loc[new_id, 'SURVEY_DATE'] = int(mg.t2_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "            glacier_pdd.loc[new_id, 'SD_PLATFORM_METHOD'] = SD_PLATFORM_METHOD # must be determined\n",
    "            REMARKS_pdd = REMARKS_pdd + ' Survey date method: %s.' % SD_METHOD\n",
    "            glacier_pdd.loc[new_id, 'REFERENCE_DATE'] = int(mg.t1_year *10000 + 9999)  # in order to fulfill the requirements (month/day unknown)\n",
    "            glacier_pdd.loc[new_id, 'RD_PLATFORM_METHOD'] = RD_PLATFORM_METHOD   # must be determined\n",
    "            REMARKS_pdd = REMARKS_pdd + ' Reference date method: %s.' % RD_METHOD\n",
    "            #glacier_pdd.PUB_IN_FOG = PUB_DATE      # not needed in data submission form\n",
    "            glacier_pdd.loc[new_id, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "            glacier_pdd.loc[new_id, 'SPONS_AGENCY'] = AGENCY\n",
    "            glacier_pdd.loc[new_id, 'REFERENCE'] = REFERENCE\n",
    "            REMARKS_pdd = REMARKS_pdd + ' ID SGI 1973: %s.' % mg.ID_SGI1973.iloc[0]\n",
    "            REMARKS_pdd = REMARKS_pdd + ' ID SGI 2010: %s.' % mg.Code_SGI2010.iloc[0]\n",
    "            # at the very end \n",
    "            glacier_pdd.loc[new_id, 'REMARKS'] = REMARKS_pdd\n",
    "\n",
    "            new_pdd = pd.concat([new_pdd, glacier_pdd], ignore_index=True)\n",
    "                                                          \n",
    "                                                          \n",
    "            # Fill PDB\n",
    "            glacier_pdb.loc[new_id, 'POLITICAL_UNIT'] = POL_UNIT\n",
    "            glacier_pdb.loc[new_id, 'NAME'] = name_to_FoG(mg_ll.Names.iloc[0].upper(),name_adjust_FoG, hot_list, special_names)\n",
    "            glacier_pdb.loc[new_id, 'WGMS_ID'] = new_id\n",
    "            glacier_pdb.loc[new_id, 'YEAR'] = mg.t2_year.iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'HIGHEST_ELEVATION'] = mg_ll['max_elevation (masl)'].iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'MEDIAN_ELEVATION'] = mg_ll['median_elevation (masl)'].iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'LOWEST_ELEVATION'] = mg_ll['min_elevation (masl)'].iloc[0]\n",
    "            #glacier_pdb.loc[new_id, 'ELEVATION_UNC'] = np.nan\n",
    "            glacier_pdb.loc[new_id, 'LENGTH'] = round(mg_ll['length (km)'].iloc[0], 2)\n",
    "            #glacier_pdb.loc[new_id, 'LENGTH_UNC'] = mg_ll['length (km)'].iloc[0] * LENGTH_UNC_FACTOR\n",
    "            glacier_pdb.loc[new_id, 'AREA'] = round(mg_ll['area(km2)'].iloc[0], 3)\n",
    "            #glacier_pdb.loc[new_id, 'AREA_UNC'] = round(area_unc(mg.area_t1_km2.iloc[0]), 2)\n",
    "            glacier_pdb.loc[new_id, 'SURVEY_DATE'] = mg_ll.year.iloc[0]\n",
    "            glacier_pdb.loc[new_id, 'SURVEY_PLATFORM_METHOD'] = SD_PLATFORM_METHOD\n",
    "            REMARKS_pdb = REMARKS_pdb + ' Survey date method: %s.' % SD_METHOD\n",
    "            glacier_pdb.loc[new_id, 'INVESTIGATOR'] = INVESTIGATOR\n",
    "            glacier_pdb.loc[new_id, 'SPONS_AGENCY'] = AGENCY\n",
    "            glacier_pdb.loc[new_id, 'REFERENCE'] = REFERENCE\n",
    "            glacier_pdb.loc[new_id, 'REMARKS'] = REMARKS_pdb\n",
    "\n",
    "            new_pdb = pd.concat([new_pdb, glacier_pdb], ignore_index=True)\n",
    "                                                          \n",
    "    return new_pda, new_pdb, new_pdd, new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(new_pda, new_pdb, new_pdd, new_id_range) = create_entries_new_id(pda, pdd, pdfll, pdf, new_pda, new_pdb, new_pdd, new_id, new_id_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the GLIMS IDs in PDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have already put the same DF into both functions taking over IDs and creating new ones, so we don't need to concat them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 glaciers are non im GLIMS\n"
     ]
    }
   ],
   "source": [
    "new_pda['GLIMS_ID'] = np.nan\n",
    "\n",
    "ct=0\n",
    "for sgi_2010_id in new_pda.SGI_2010_ID.values:\n",
    "    try:\n",
    "        new_pda.loc[new_pda[new_pda.SGI_2010_ID == sgi_2010_id].index, 'GLIMS_ID'] = glims[glims.local_id == sgi_2010_id].glac_id.iloc[0]\n",
    "    except IndexError:\n",
    "        #print('Not in GLIMS:',new_pda[new_pda.SGI_2010_ID == sgi_2010_id].NAME.iloc[0], sgi_2010_id)\n",
    "        ct += 1\n",
    "        continue\n",
    "\n",
    "# Some glaciers don't have a GLIMS entry due to their size (~0.2km2)\n",
    "print('%s glaciers are non im GLIMS' % ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are still name duplicates: Try and get the Kanton abbreviations to make them separable more easily (doesn't always work, but at least sometimes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read Kanton borders\n",
    "fc = fiona.open(ch_adm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "namedupl_pda = [item for item, count in collections.Counter(new_pda.NAME.values).items() if count > 1]\n",
    "\n",
    "for name in namedupl_pda:\n",
    "    id_list = new_pda[new_pda.NAME == name].WGMS_ID.values\n",
    "    \n",
    "    for wgms_id in id_list:\n",
    "        print(wgms_id)\n",
    "        lon = new_pda[new_pda.WGMS_ID == wgms_id].LONGITUDE.iloc[0]\n",
    "        lat = new_pda[new_pda.WGMS_ID == wgms_id].LATITUDE.iloc[0]\n",
    "        print(lon, lat)\n",
    "        point = Point(lon,lat)\n",
    "        \n",
    "        for feature in fc:\n",
    "            if shape(feature['geometry']).contains(point):\n",
    "                new_pda.loc[new_pda[new_pda.WGMS_ID == wgms_id].index,'NAME'] = name + ' ' + feature['properties']['HASC_1'].split('.')[1]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "namedupl_pdb = [item for item, count in collections.Counter(new_pdb.NAME.values).items() if count > 1]\n",
    "\n",
    "for name in namedupl_pdb:\n",
    "    id_list = new_pdb[new_pdb.NAME == name].WGMS_ID.values\n",
    "    \n",
    "    for wgms_id in id_list:\n",
    "        print(wgms_id)\n",
    "        try:\n",
    "            lon = new_pda[new_pda.WGMS_ID == wgms_id].LONGITUDE.iloc[0]\n",
    "            lat = new_pda[new_pda.WGMS_ID == wgms_id].LATITUDE.iloc[0]\n",
    "            print(lon, lat)\n",
    "            point = Point(lon,lat)\n",
    "        except IndexError: # FoG entry already present\n",
    "            print(name,wgms_id)\n",
    "            continue\n",
    "        \n",
    "        for feature in fc:\n",
    "            if shape(feature['geometry']).contains(point):\n",
    "                new_pdb.loc[new_pdb[new_pdb.WGMS_ID == wgms_id].index,'NAME'] = name + ' ' + feature['properties']['HASC_1'].split('.')[1]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "namedupl_pdd = [item for item, count in collections.Counter(new_pdd.NAME.values).items() if count > 1]\n",
    "\n",
    "for name in namedupl_pdd:\n",
    "    id_list = new_pdd[new_pdd.NAME == name].WGMS_ID.values\n",
    "    \n",
    "    for wgms_id in id_list:\n",
    "        print(wgms_id)\n",
    "        try:\n",
    "            lon = new_pda[new_pda.WGMS_ID == wgms_id].LONGITUDE.iloc[0]\n",
    "            lat = new_pda[new_pda.WGMS_ID == wgms_id].LATITUDE.iloc[0]\n",
    "            print(lon, lat)\n",
    "            point = Point(lon,lat)\n",
    "        except IndexError: # FoG entry already present\n",
    "            print(name,wgms_id)\n",
    "            continue\n",
    "        \n",
    "        for feature in fc:\n",
    "            if shape(feature['geometry']).contains(point):\n",
    "                new_pdd.loc[new_pdd[new_pdd.WGMS_ID == wgms_id].index,'NAME'] = name + ' ' + feature['properties']['HASC_1'].split('.')[1]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the columns in order to be able to insert this easily into the data submission form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pda = new_pda[['POLTITICAL_UNIT', 'NAME', 'WGMS_ID', 'RIVER_BASIN', 'FREE_POSITION', 'LOCAL_CODE', 'LOCAL_PSFG', 'GEN_LOCATION', 'SPEC_LOCATION', 'LATITUDE', 'LONGITUDE', 'PRIM_CLASSIFIC', 'FORM', 'FRONTAL_CHARS', 'EXPOS_ACC_AREA', 'EXPOS_ABL_AREA', 'PARENT_GLACIER', 'REMARKS', 'REGION', 'SUBREGION', 'GLIMS_ID']]\n",
    "new_pdb = new_pdb[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'HIGHEST_ELEVATION', 'MEDIAN_ELEVATION', 'LOWEST_ELEVATION', 'ELEVATION_UNC', 'LENGTH', 'LENGTH_UNC', 'AREA', 'AREA_UNC', 'SURVEY_DATE', 'SURVEY_PLATFORM_METHOD', 'INVESTIGATOR', 'SPONS_AGENCY', 'REFERENCE', 'REMARKS']]\n",
    "new_pdd = new_pdd[['POLITICAL_UNIT', 'NAME', 'WGMS_ID', 'YEAR', 'LOWER_BOUND', 'UPPER_BOUND', 'AREA_SURVEY_YEAR', 'AREA_CHANGE', 'AREA_CHANGE_UNC', 'THICKNESS_CHG', 'THICKNESS_CHG_UNC', 'VOLUME_CHANGE', 'VOLUME_CHANGE_UNC', 'SURVEY_DATE', 'SD_PLATFORM_METHOD', 'REFERENCE_DATE', 'RD_PLATFORM_METHOD', 'INVESTIGATOR', 'SPONS_AGENCY', 'REFERENCE', 'REMARKS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Excel format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_pda.to_excel('c:\\\\users\\\\jlandman\\\\Desktop\\\\PDA_submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pdb.to_excel('c:\\\\users\\\\jlandman\\\\Desktop\\\\PDB_submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_pdd.to_excel('c:\\\\users\\\\jlandman\\\\Desktop\\\\PDD_submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(links.keys())-set(new_pda.NAME.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1221"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(new_pda.NAME.values)-set([name_to_FoG(i,name_adjust_FoG, hot_list, special_names) for i in listlist])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to RGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check is point is within an RGI polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgi = fiona.open(rgi_CE)\n",
    "rgi_links = new_pda.copy()\n",
    "rgi_links_present = pda.copy()\n",
    "rgi_links['RGI_ID'] = np.nan\n",
    "rgi_links_present['RGI_ID'] = np.nan\n",
    "\n",
    "for fog_id in rgi_links.WGMS_ID.values:\n",
    "    ix = rgi_links.index[rgi_links.WGMS_ID == fog_id]\n",
    "    print(fog_id)\n",
    "    lon = rgi_links[rgi_links.WGMS_ID == fog_id].LONGITUDE.iloc[0]\n",
    "    lat = rgi_links[rgi_links.WGMS_ID == fog_id].LATITUDE.iloc[0]\n",
    "    print(lon, lat)\n",
    "    point = Point(lon,lat)\n",
    "\n",
    "    for feature in rgi:\n",
    "        if shape(feature['geometry']).contains(point):\n",
    "            print(feature['properties']['RGIId'], ix)\n",
    "            rgi_links.loc[ix, 'RGI_ID'] = feature['properties']['RGIId']\n",
    "\n",
    "            \n",
    "rgi_links.to_csv('sgi2010_rgi_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rgi_links.dropna(subset=['RGI_ID']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
